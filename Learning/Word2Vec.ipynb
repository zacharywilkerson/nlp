{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7779045",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "___\n",
    "## Notes\n",
    "In this notebook, we will discuss the word2vec algorithm.\n",
    "\n",
    "Specifically, we break our discussion down into the following sections:\n",
    "> [Overview](#Overview:-word2vec)\n",
    ">\n",
    "> [Implementation](#Implementation)\n",
    ">\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Pre-Trained Embeddings](#Pre-Trained-Embeddings)\n",
    ">\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Training Embeddings](#Training-Embeddings)\n",
    ">\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Preparing Word Vectors for ML Models](#Preparing-Word-Vectors-for-ML-Models)\n",
    "\n",
    "We finish the notebook off with a [review](#Review) of everything discussed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9445463",
   "metadata": {},
   "source": [
    "## Overview\n",
    "> **Word2Vec** is an embedding algorithm based on a shllow, two-layer neural network that takes a text corpus as input and outputs a vector representation for each word in the corpus. \n",
    "> \n",
    "> There are many ways to train a word2vec mode, but for now we will look at the **skip-gram** method, which looks at a window of words to the left and right of a given word to determine its context and map it into a vector space. \n",
    "> \n",
    "> This idea is based on the saying: \"*you shall know a word by the company it keeps.*\" \n",
    ">\n",
    "> From this vector representation, we can determine **word similarity**. A popular way to calculate word similarity is via **cosine similarity**, which determines the cosine value of the angle between the two word vectors you are trying to determine the similarity of. Therefore, if the angle between the word vectors is small, the similarity is very high. \n",
    ">\n",
    "> There vector representations also give way to the construction of word analogies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba878dde",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "> When using word2vec, we can either:\n",
    "> 1. use pre-trained embeddings, where a word2vec model has already been trained on a large corpus of text:\n",
    ">     - `glove-twitter-{25/50/100/200}`\n",
    ">     - `glove-wiki-gigaword-{50/100/200/300}`\n",
    ">     - `word2vec-google-news-300`\n",
    ">     - `word2vec-ruscorpora-news-300`\n",
    ">     - and a few [others](https://radimrehurek.com/gensim/models/word2vec.html)...\n",
    "> 2. train embeddings using our own set of data.\n",
    ">\n",
    "> Once we have our embeddings, we need to do a bit more prep word to get the vector representations ready for input into a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4742a",
   "metadata": {},
   "source": [
    "### Pre-Trained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f1843",
   "metadata": {},
   "source": [
    "We start by importing `gensim`, a package that comes with a bunch of pre-trained embeddings build in, and loading the `glove-wiki-gigaword-100` embedding (the 100 represents the length each vector should be in the embedding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b6a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9e80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b017a19",
   "metadata": {},
   "source": [
    "Now, we'll examine the word vector for the word \"king\", and find words most similar to \"king\" based on our embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ccdd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n",
       "       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n",
       "       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n",
       "       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n",
       "        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n",
       "        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n",
       "       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n",
       "        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n",
       "        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n",
       "       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n",
       "        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n",
       "       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n",
       "        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n",
       "       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n",
       "       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n",
       "        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n",
       "       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53488317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7682329416275024),\n",
       " ('queen', 0.7507690787315369),\n",
       " ('son', 0.7020888328552246),\n",
       " ('brother', 0.6985775828361511),\n",
       " ('monarch', 0.6977890729904175),\n",
       " ('throne', 0.691999077796936),\n",
       " ('kingdom', 0.6811409592628479),\n",
       " ('father', 0.6802029013633728),\n",
       " ('emperor', 0.6712858080863953),\n",
       " ('ii', 0.6676074266433716)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.most_similar('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ded66",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afae8b",
   "metadata": {},
   "source": [
    "### Training Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42dd28c",
   "metadata": {},
   "source": [
    "Let's try to train our own embeddings using the `SMSSpamCollection.tsv` file. Start by loading in, and cleaning up, the file. \n",
    "\n",
    "While we could clean the data ourselves, we'll make use of the `gensim` `simple_preprocess` function. This will remove punctuation and stopwords before tokenizing the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f96874b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>[ve, been, searching, for, the, right, words, to, thank, you, for, this, breather, promise, wont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>[have, date, on, sunday, with, will]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                            clean_text  \n",
       "0  [ve, been, searching, for, the, right, words, to, thank, you, for, this, breather, promise, wont...  \n",
       "1  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n",
       "2                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  \n",
       "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]  \n",
       "4                                                                 [have, date, on, sunday, with, will]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "\n",
    "messages = pd.read_csv('SMSSpamCollection.tsv', sep='\\t', header=None)\n",
    "messages.columns = ['label','text']\n",
    "\n",
    "messages['clean_text'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744f0e1",
   "metadata": {},
   "source": [
    "Now, go ahead and split our data up into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620f1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages['clean_text'],messages['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acf027",
   "metadata": {},
   "source": [
    "We need to train our word2vec model now. For now, we'll set:\n",
    "- `vector_size=100`: the length of the word embedding vectors (aka the dimensions the word gets mapped into)\n",
    "- `window=5`: the number of words to look at for context (5 would mean 2 to the left and 2 to the right of the current word)\n",
    "- `min_count=2`: the number of times a word needs to appear in the corpus to create a vector embedding for that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "079f98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6cc369",
   "metadata": {},
   "source": [
    "Now, we'll examine the word vector for the word \"king\", and find words most similar to \"king\" based on our embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386c2fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04996508,  0.06191731,  0.01920232, -0.00921991, -0.00794392,\n",
       "       -0.11238229,  0.03144125,  0.15554667, -0.04757956, -0.06054191,\n",
       "       -0.02493219, -0.08994311, -0.02334521,  0.03916509,  0.02084255,\n",
       "       -0.03985299, -0.0059781 , -0.0659265 , -0.00192455, -0.13866237,\n",
       "        0.033167  ,  0.04735364,  0.03730169, -0.02935965, -0.00567448,\n",
       "       -0.01049724, -0.04019884, -0.05439038, -0.07118474,  0.03066384,\n",
       "        0.07288796, -0.00085214,  0.03131102, -0.05915679, -0.03692801,\n",
       "        0.08658414,  0.04561409, -0.05220363, -0.01140274, -0.1216219 ,\n",
       "        0.02775528, -0.04251336, -0.0558888 , -0.00066932,  0.05631372,\n",
       "       -0.04125058, -0.04528016, -0.01465464,  0.05670632,  0.03521145,\n",
       "        0.04856405, -0.06812292, -0.00350109, -0.00766639, -0.0172387 ,\n",
       "        0.05529414,  0.04766516,  0.00591104, -0.09423443,  0.02206806,\n",
       "        0.01064999, -0.00531434, -0.00255395, -0.01964384, -0.07075865,\n",
       "        0.06811004,  0.02430508,  0.07080574, -0.07174548,  0.07144115,\n",
       "       -0.04561865,  0.06563386,  0.09413301, -0.01821867,  0.06079134,\n",
       "        0.03127601,  0.01014564, -0.02310837, -0.06519237, -0.0004825 ,\n",
       "       -0.05120867, -0.01404801, -0.0786704 ,  0.10532764, -0.01349606,\n",
       "       -0.02429941,  0.02761989,  0.06669828,  0.08160085,  0.02958917,\n",
       "        0.11060236,  0.05135116,  0.00837148,  0.03927771,  0.13166027,\n",
       "        0.06113048,  0.04012184, -0.04422384,  0.00614625, -0.04140215],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e8ee05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('again', 0.9946290850639343),\n",
       " ('girl', 0.9946222901344299),\n",
       " ('think', 0.9945281744003296),\n",
       " ('there', 0.9945186376571655),\n",
       " ('done', 0.9944351315498352),\n",
       " ('same', 0.9944155812263489),\n",
       " ('why', 0.9943594336509705),\n",
       " ('wait', 0.9943505525588989),\n",
       " ('in', 0.9943446516990662),\n",
       " ('very', 0.9943395256996155)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff90e25",
   "metadata": {},
   "source": [
    "`Note`: This embedding don't make as much sense as the one we obtained from the pre-trained model earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aaf159",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0925ee",
   "metadata": {},
   "source": [
    "### Preparing Word Vectors for ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c1d76",
   "metadata": {},
   "source": [
    "First, we'll take a look at the words that have embeddings in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881a0642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'you',\n",
       " 'the',\n",
       " 'and',\n",
       " 'is',\n",
       " 'in',\n",
       " 'me',\n",
       " 'it',\n",
       " 'my',\n",
       " 'for',\n",
       " 'your',\n",
       " 'of',\n",
       " 'call',\n",
       " 'have',\n",
       " 'that',\n",
       " 'on',\n",
       " 'now',\n",
       " 'are',\n",
       " 'can',\n",
       " 'so',\n",
       " 'not',\n",
       " 'but',\n",
       " 'we',\n",
       " 'or',\n",
       " 'at',\n",
       " 'if',\n",
       " 'do',\n",
       " 'will',\n",
       " 'ur',\n",
       " 'no',\n",
       " 'with',\n",
       " 'get',\n",
       " 'be',\n",
       " 'just',\n",
       " 'this',\n",
       " 'lt',\n",
       " 'gt',\n",
       " 'how',\n",
       " 'up',\n",
       " 'what',\n",
       " 'go',\n",
       " 'when',\n",
       " 'ok',\n",
       " 'from',\n",
       " 'out',\n",
       " 'free',\n",
       " 'know',\n",
       " 'all',\n",
       " 'll',\n",
       " 'good',\n",
       " 'am',\n",
       " 'then',\n",
       " 'come',\n",
       " 'like',\n",
       " 'he',\n",
       " 'its',\n",
       " 'was',\n",
       " 'there',\n",
       " 'got',\n",
       " 'day',\n",
       " 'only',\n",
       " 'love',\n",
       " 'time',\n",
       " 'want',\n",
       " 'text',\n",
       " 'send',\n",
       " 'as',\n",
       " 'one',\n",
       " 'going',\n",
       " 'about',\n",
       " 'stop',\n",
       " 'home',\n",
       " 'lor',\n",
       " 'see',\n",
       " 'need',\n",
       " 'back',\n",
       " 'txt',\n",
       " 'by',\n",
       " 'still',\n",
       " 'don',\n",
       " 'today',\n",
       " 'reply',\n",
       " 'she',\n",
       " 'sorry',\n",
       " 'da',\n",
       " 'our',\n",
       " 'dont',\n",
       " 'hi',\n",
       " 'mobile',\n",
       " 'think',\n",
       " 'phone',\n",
       " 'some',\n",
       " 'tell',\n",
       " 'take',\n",
       " 'please',\n",
       " 'later',\n",
       " 'any',\n",
       " 'new',\n",
       " 'they',\n",
       " 'pls',\n",
       " 'did',\n",
       " 'who',\n",
       " 'week',\n",
       " 're',\n",
       " 'oh',\n",
       " 'her',\n",
       " 'been',\n",
       " 'well',\n",
       " 'an',\n",
       " 'night',\n",
       " 'dear',\n",
       " 'where',\n",
       " 'him',\n",
       " 'msg',\n",
       " 'claim',\n",
       " 'much',\n",
       " 'here',\n",
       " 'hope',\n",
       " 'hey',\n",
       " 'has',\n",
       " 'make',\n",
       " 'yes',\n",
       " 'too',\n",
       " 'more',\n",
       " 'had',\n",
       " 'happy',\n",
       " 'give',\n",
       " 'number',\n",
       " 'work',\n",
       " 'wat',\n",
       " 've',\n",
       " 'great',\n",
       " 'tomorrow',\n",
       " 'message',\n",
       " 'say',\n",
       " 'right',\n",
       " 'way',\n",
       " 'prize',\n",
       " 'already',\n",
       " 'cash',\n",
       " 'amp',\n",
       " 'ask',\n",
       " 'should',\n",
       " 'won',\n",
       " 'www',\n",
       " 'after',\n",
       " 'really',\n",
       " 'yeah',\n",
       " 'im',\n",
       " 'thanks',\n",
       " 'miss',\n",
       " 'meet',\n",
       " 'said',\n",
       " 'let',\n",
       " 'find',\n",
       " 'babe',\n",
       " 'why',\n",
       " 'them',\n",
       " 'doing',\n",
       " 'life',\n",
       " 'anything',\n",
       " 'us',\n",
       " 'also',\n",
       " 'very',\n",
       " 'last',\n",
       " 'win',\n",
       " 'uk',\n",
       " 'morning',\n",
       " 'sure',\n",
       " 'lol',\n",
       " 'care',\n",
       " 'would',\n",
       " 'something',\n",
       " 'wait',\n",
       " 'cos',\n",
       " 'min',\n",
       " 'gud',\n",
       " 'com',\n",
       " 'keep',\n",
       " 'again',\n",
       " 'contact',\n",
       " 'someone',\n",
       " 'urgent',\n",
       " 'first',\n",
       " 'his',\n",
       " 'every',\n",
       " 'cant',\n",
       " 'pick',\n",
       " 'nice',\n",
       " 'over',\n",
       " 'could',\n",
       " 'sent',\n",
       " 'off',\n",
       " 'feel',\n",
       " 'tonight',\n",
       " 'before',\n",
       " 'help',\n",
       " 'customer',\n",
       " 'sleep',\n",
       " 'around',\n",
       " 'gonna',\n",
       " 'service',\n",
       " 'per',\n",
       " 'late',\n",
       " 'many',\n",
       " 'nokia',\n",
       " 'mins',\n",
       " 'went',\n",
       " 'always',\n",
       " 'chat',\n",
       " 'down',\n",
       " 'box',\n",
       " 'buy',\n",
       " 'even',\n",
       " 'money',\n",
       " 'told',\n",
       " 'soon',\n",
       " 'were',\n",
       " 'people',\n",
       " 'friends',\n",
       " 'sms',\n",
       " 'which',\n",
       " 'thing',\n",
       " 'may',\n",
       " 'other',\n",
       " 'friend',\n",
       " 'getting',\n",
       " 'next',\n",
       " 'tone',\n",
       " 'name',\n",
       " 'leave',\n",
       " 'ya',\n",
       " 'man',\n",
       " 'place',\n",
       " 'special',\n",
       " 'pm',\n",
       " 'wish',\n",
       " 'fine',\n",
       " 'year',\n",
       " 'things',\n",
       " 'haha',\n",
       " 'use',\n",
       " 'dun',\n",
       " 'holiday',\n",
       " 'hello',\n",
       " 'th',\n",
       " 'co',\n",
       " 'same',\n",
       " 'st',\n",
       " 'few',\n",
       " 'god',\n",
       " 'ppm',\n",
       " 'talk',\n",
       " 'days',\n",
       " 'try',\n",
       " 'heart',\n",
       " 'stuff',\n",
       " 'best',\n",
       " 'finish',\n",
       " 'smile',\n",
       " 'lunch',\n",
       " 'cs',\n",
       " 'person',\n",
       " 'wan',\n",
       " 'bit',\n",
       " 'live',\n",
       " 'waiting',\n",
       " 'guaranteed',\n",
       " 'yet',\n",
       " 'job',\n",
       " 'half',\n",
       " 'thought',\n",
       " 'yup',\n",
       " 'better',\n",
       " 'thk',\n",
       " 'line',\n",
       " 'coming',\n",
       " 'being',\n",
       " 'ready',\n",
       " 'done',\n",
       " 'meeting',\n",
       " 'cool',\n",
       " 'play',\n",
       " 'pobox',\n",
       " 'trying',\n",
       " 'end',\n",
       " 'chance',\n",
       " 'ill',\n",
       " 'account',\n",
       " 'car',\n",
       " 'because',\n",
       " 'receive',\n",
       " 'class',\n",
       " 'lot',\n",
       " 'never',\n",
       " 'bt',\n",
       " 'thats',\n",
       " 'xxx',\n",
       " 'check',\n",
       " 'draw',\n",
       " 'house',\n",
       " 'might',\n",
       " 'yo',\n",
       " 'mind',\n",
       " 'didn',\n",
       " 'rate',\n",
       " 'hear',\n",
       " 'boy',\n",
       " 'enjoy',\n",
       " 'nothing',\n",
       " 'sir',\n",
       " 'having',\n",
       " 'shit',\n",
       " 'office',\n",
       " 'guys',\n",
       " 'called',\n",
       " 'month',\n",
       " 'wanna',\n",
       " 'baby',\n",
       " 'video',\n",
       " 'dat',\n",
       " 'liao',\n",
       " 'cost',\n",
       " 'long',\n",
       " 'real',\n",
       " 'than',\n",
       " 'jus',\n",
       " 'big',\n",
       " 'lar',\n",
       " 'sweet',\n",
       " 'world',\n",
       " 'problem',\n",
       " 'eat',\n",
       " 'latest',\n",
       " 'offer',\n",
       " 'another',\n",
       " 'ah',\n",
       " 'birthday',\n",
       " 'forgot',\n",
       " 'shows',\n",
       " 'start',\n",
       " 'guess',\n",
       " 'between',\n",
       " 'orange',\n",
       " 'girl',\n",
       " 'looking',\n",
       " 'watching',\n",
       " 'wk',\n",
       " 'camera',\n",
       " 'once',\n",
       " 'den',\n",
       " 'nd',\n",
       " 'maybe',\n",
       " 'probably',\n",
       " 'plan',\n",
       " 'landline',\n",
       " 'word',\n",
       " 'easy',\n",
       " 'pa',\n",
       " 'apply',\n",
       " 'room',\n",
       " 'thanx',\n",
       " 'selected',\n",
       " 'two',\n",
       " 'award',\n",
       " 'does',\n",
       " 'ever',\n",
       " 'pay',\n",
       " 'true',\n",
       " 'sat',\n",
       " 'network',\n",
       " 'bad',\n",
       " 'tv',\n",
       " 'dunno',\n",
       " 'actually',\n",
       " 'okay',\n",
       " 'kiss',\n",
       " 'wont',\n",
       " 'dinner',\n",
       " 'though',\n",
       " 'awarded',\n",
       " 'left',\n",
       " 'details',\n",
       " 'reach',\n",
       " 'missing',\n",
       " 'face',\n",
       " 'bus',\n",
       " 'tones',\n",
       " 'leh',\n",
       " 'quite',\n",
       " 'price',\n",
       " 'hrs',\n",
       " 'bed',\n",
       " 'part',\n",
       " 'princess',\n",
       " 'afternoon',\n",
       " 'didnt',\n",
       " 'evening',\n",
       " 'xx',\n",
       " 'ringtone',\n",
       " 'calls',\n",
       " 'pain',\n",
       " 'fun',\n",
       " 'dad',\n",
       " 'texts',\n",
       " 'po',\n",
       " 'hour',\n",
       " 'anyway',\n",
       " 'luv',\n",
       " 'made',\n",
       " 'watch',\n",
       " 'fuck',\n",
       " 'guy',\n",
       " 'means',\n",
       " 'most',\n",
       " 'speak',\n",
       " 'asked',\n",
       " 'nite',\n",
       " 'shall',\n",
       " 'code',\n",
       " 'aight',\n",
       " 'put',\n",
       " 'working',\n",
       " 'little',\n",
       " 'wife',\n",
       " 'hav',\n",
       " 'tmr',\n",
       " 'plz',\n",
       " 'weekend',\n",
       " 'says',\n",
       " 'plus',\n",
       " 'worry',\n",
       " 'without',\n",
       " 'collect',\n",
       " 'look',\n",
       " 'times',\n",
       " 'haven',\n",
       " 'remember',\n",
       " 'everything',\n",
       " 'shopping',\n",
       " 'goes',\n",
       " 'bring',\n",
       " 'thank',\n",
       " 'saw',\n",
       " 'years',\n",
       " 'enough',\n",
       " 'double',\n",
       " 'yesterday',\n",
       " 'bored',\n",
       " 'else',\n",
       " 'school',\n",
       " 'wants',\n",
       " 'online',\n",
       " 'hair',\n",
       " 'entry',\n",
       " 'book',\n",
       " 'collection',\n",
       " 'sexy',\n",
       " 'into',\n",
       " 'hot',\n",
       " 'stay',\n",
       " 'decimal',\n",
       " 'weekly',\n",
       " 'order',\n",
       " 'haf',\n",
       " 'tried',\n",
       " 'show',\n",
       " 'yours',\n",
       " 'early',\n",
       " 'net',\n",
       " 'until',\n",
       " 'came',\n",
       " 'able',\n",
       " 'join',\n",
       " 'valid',\n",
       " 'delivery',\n",
       " 'dreams',\n",
       " 'mail',\n",
       " 'wanted',\n",
       " 'attempt',\n",
       " 'minutes',\n",
       " 'coz',\n",
       " 'wake',\n",
       " 'dis',\n",
       " 'national',\n",
       " 'hours',\n",
       " 'till',\n",
       " 'age',\n",
       " 'id',\n",
       " 'both',\n",
       " 'wot',\n",
       " 'while',\n",
       " 'missed',\n",
       " 'must',\n",
       " 'abt',\n",
       " 'messages',\n",
       " 'game',\n",
       " 'words',\n",
       " 'oso',\n",
       " 'juz',\n",
       " 'mob',\n",
       " 'thinking',\n",
       " 'optout',\n",
       " 'havent',\n",
       " 'wif',\n",
       " 'top',\n",
       " 'gift',\n",
       " 'run',\n",
       " 'lei',\n",
       " 'those',\n",
       " 'ard',\n",
       " 'friendship',\n",
       " 'simple',\n",
       " 'tot',\n",
       " 'since',\n",
       " 'music',\n",
       " 'date',\n",
       " 'important',\n",
       " 'question',\n",
       " 'drop',\n",
       " 'til',\n",
       " 'food',\n",
       " 'these',\n",
       " 'pics',\n",
       " 'wid',\n",
       " 'xmas',\n",
       " 'hurt',\n",
       " 'sae',\n",
       " 'calling',\n",
       " 'de',\n",
       " 'town',\n",
       " 'full',\n",
       " 'old',\n",
       " 'finished',\n",
       " 'email',\n",
       " 'nt',\n",
       " 'dude',\n",
       " 'change',\n",
       " 'tomo',\n",
       " 'okie',\n",
       " 'goin',\n",
       " 'started',\n",
       " 'address',\n",
       " 'driving',\n",
       " 'believe',\n",
       " 'saying',\n",
       " 'ring',\n",
       " 'movie',\n",
       " 'alright',\n",
       " 'wen',\n",
       " 'shop',\n",
       " 'mths',\n",
       " 'busy',\n",
       " 'either',\n",
       " 'touch',\n",
       " 'await',\n",
       " 'making',\n",
       " 'comes',\n",
       " 'points',\n",
       " 'services',\n",
       " 'private',\n",
       " 'family',\n",
       " 'post',\n",
       " 'anytime',\n",
       " 'pic',\n",
       " 'lets',\n",
       " 'sleeping',\n",
       " 'takes',\n",
       " 'http',\n",
       " 'everyone',\n",
       " 'test',\n",
       " 'saturday',\n",
       " 'eve',\n",
       " 'congrats',\n",
       " 'away',\n",
       " 'games',\n",
       " 'aft',\n",
       " 'gd',\n",
       " 'todays',\n",
       " 'open',\n",
       " 'feeling',\n",
       " 'winner',\n",
       " 'available',\n",
       " 'drink',\n",
       " 'makes',\n",
       " 'smiling',\n",
       " 'answer',\n",
       " 'tho',\n",
       " 'doesn',\n",
       " 'poly',\n",
       " 'ni',\n",
       " 'hold',\n",
       " 'statement',\n",
       " 'happen',\n",
       " 'far',\n",
       " 'brother',\n",
       " 'chikku',\n",
       " 'cause',\n",
       " 'forget',\n",
       " 'mobileupd',\n",
       " 'noe',\n",
       " 'worth',\n",
       " 'unsubscribe',\n",
       " 'msgs',\n",
       " 'yourself',\n",
       " 'story',\n",
       " 'minute',\n",
       " 'together',\n",
       " 'sister',\n",
       " 'search',\n",
       " 'gr',\n",
       " 'college',\n",
       " 'pub',\n",
       " 'wil',\n",
       " 'beautiful',\n",
       " 'mean',\n",
       " 'close',\n",
       " 'leaving',\n",
       " 'update',\n",
       " 'decided',\n",
       " 'walk',\n",
       " 'huh',\n",
       " 'drive',\n",
       " 'sad',\n",
       " 'set',\n",
       " 'head',\n",
       " 'used',\n",
       " 'sch',\n",
       " 'awesome',\n",
       " 'anyone',\n",
       " 'secret',\n",
       " 'company',\n",
       " 'treat',\n",
       " 'card',\n",
       " 'mine',\n",
       " 'dating',\n",
       " 'crazy',\n",
       " 'reason',\n",
       " 'opt',\n",
       " 'kind',\n",
       " 'second',\n",
       " 'loving',\n",
       " 'lucky',\n",
       " 'bonus',\n",
       " 'fast',\n",
       " 'smoke',\n",
       " 'took',\n",
       " 'colour',\n",
       " 'sun',\n",
       " 'charge',\n",
       " 'lose',\n",
       " 'carlos',\n",
       " 'whats',\n",
       " 'angry',\n",
       " 'nyt',\n",
       " 'phones',\n",
       " 'content',\n",
       " 'mates',\n",
       " 'thinks',\n",
       " 'visit',\n",
       " 'sounds',\n",
       " 'hand',\n",
       " 'club',\n",
       " 'fr',\n",
       " 'frm',\n",
       " 'suite',\n",
       " 'mom',\n",
       " 'lesson',\n",
       " 'trip',\n",
       " 'pretty',\n",
       " 'goodmorning',\n",
       " 'pounds',\n",
       " 'taking',\n",
       " 'fone',\n",
       " 'nope',\n",
       " 'lovely',\n",
       " 'found',\n",
       " 'quiz',\n",
       " 'case',\n",
       " 'identifier',\n",
       " 'expires',\n",
       " 'final',\n",
       " 'light',\n",
       " 'oredi',\n",
       " 'wit',\n",
       " 'land',\n",
       " 'type',\n",
       " 'knw',\n",
       " 'prob',\n",
       " 'credit',\n",
       " 'savamob',\n",
       " 'tired',\n",
       " 'rs',\n",
       " 'die',\n",
       " 'each',\n",
       " 'operator',\n",
       " 'least',\n",
       " 'luck',\n",
       " 'mate',\n",
       " 'hl',\n",
       " 'earlier',\n",
       " 'boytoy',\n",
       " 'parents',\n",
       " 'listen',\n",
       " 'ish',\n",
       " 'gym',\n",
       " 'hmm',\n",
       " 'party',\n",
       " 'darlin',\n",
       " 'enter',\n",
       " 'rental',\n",
       " 'whatever',\n",
       " 'motorola',\n",
       " 'gal',\n",
       " 'gbp',\n",
       " 'chennai',\n",
       " 'info',\n",
       " 'voucher',\n",
       " 'fri',\n",
       " 'congratulations',\n",
       " 'welcome',\n",
       " 'charged',\n",
       " 'neva',\n",
       " 'row',\n",
       " 'sex',\n",
       " 'stupid',\n",
       " 'gas',\n",
       " 'isn',\n",
       " 'rite',\n",
       " 'mum',\n",
       " 'unlimited',\n",
       " 'camcorder',\n",
       " 'sis',\n",
       " 'girls',\n",
       " 'gone',\n",
       " 'dnt',\n",
       " 'mr',\n",
       " 'etc',\n",
       " 'offers',\n",
       " 'ltd',\n",
       " 'vouchers',\n",
       " 'smth',\n",
       " 'ago',\n",
       " 'ass',\n",
       " 'lands',\n",
       " 'bslvyl',\n",
       " 'wonderful',\n",
       " 'course',\n",
       " 'ha',\n",
       " 'dogging',\n",
       " 'reveal',\n",
       " 'mrng',\n",
       " 'download',\n",
       " 'sea',\n",
       " 'needs',\n",
       " 'wasn',\n",
       " 'lots',\n",
       " 'choose',\n",
       " 'happened',\n",
       " 'christmas',\n",
       " 'muz',\n",
       " 'alone',\n",
       " 'friday',\n",
       " 'wrong',\n",
       " 'hows',\n",
       " 'hard',\n",
       " 'picking',\n",
       " 'ends',\n",
       " 'na',\n",
       " 'wq',\n",
       " 'met',\n",
       " 'break',\n",
       " 'eh',\n",
       " 'heard',\n",
       " 'understand',\n",
       " 'fucking',\n",
       " 'press',\n",
       " 'wow',\n",
       " 'father',\n",
       " 'player',\n",
       " 'blue',\n",
       " 'rply',\n",
       " 'song',\n",
       " 'own',\n",
       " 'un',\n",
       " 'project',\n",
       " 'sunday',\n",
       " 'sk',\n",
       " 'john',\n",
       " 'ex',\n",
       " 'point',\n",
       " 'whole',\n",
       " 'wine',\n",
       " 'shower',\n",
       " 'remove',\n",
       " 'knew',\n",
       " 'yrs',\n",
       " 'whenever',\n",
       " 'seeing',\n",
       " 'meant',\n",
       " 'yar',\n",
       " 'log',\n",
       " 'ten',\n",
       " 'cum',\n",
       " 'hit',\n",
       " 'weeks',\n",
       " 'tc',\n",
       " 'park',\n",
       " 'fancy',\n",
       " 'numbers',\n",
       " 'supposed',\n",
       " 'couple',\n",
       " 'kate',\n",
       " 'checking',\n",
       " 'cut',\n",
       " 'laptop',\n",
       " 'loads',\n",
       " 'reading',\n",
       " 'through',\n",
       " 'jay',\n",
       " 'ac',\n",
       " 'doin',\n",
       " 'ipod',\n",
       " 'frnd',\n",
       " 'india',\n",
       " 'talking',\n",
       " 'bout',\n",
       " 'spend',\n",
       " 'frnds',\n",
       " 'caller',\n",
       " 'happiness',\n",
       " 'news',\n",
       " 'seen',\n",
       " 'sort',\n",
       " 'swing',\n",
       " 'hungry',\n",
       " 'txts',\n",
       " 'redeemed',\n",
       " 'uncle',\n",
       " 'snow',\n",
       " 'hee',\n",
       " 'march',\n",
       " 'plans',\n",
       " 'via',\n",
       " 'empty',\n",
       " 'slow',\n",
       " 'difficult',\n",
       " 'valued',\n",
       " 'gets',\n",
       " 'ge',\n",
       " 'paper',\n",
       " 'balance',\n",
       " 'within',\n",
       " 'bcoz',\n",
       " 'immediately',\n",
       " 'police',\n",
       " 'support',\n",
       " 'tel',\n",
       " 'xy',\n",
       " 'leaves',\n",
       " 'finally',\n",
       " 'direct',\n",
       " 'sound',\n",
       " 'figure',\n",
       " 'side',\n",
       " 'feels',\n",
       " 'mu',\n",
       " 'yr',\n",
       " 'invited',\n",
       " 'clean',\n",
       " 'felt',\n",
       " 'pass',\n",
       " 'almost',\n",
       " 'freemsg',\n",
       " 'rakhesh',\n",
       " 'their',\n",
       " 'hmmm',\n",
       " 'mode',\n",
       " 'lost',\n",
       " 'sending',\n",
       " 'discount',\n",
       " 'gettin',\n",
       " 'bathe',\n",
       " 'small',\n",
       " 'goodnight',\n",
       " 'rest',\n",
       " 'lect',\n",
       " 'cr',\n",
       " 'sell',\n",
       " 'energy',\n",
       " 'area',\n",
       " 'red',\n",
       " 'loved',\n",
       " 'wana',\n",
       " 'complimentary',\n",
       " 'lovable',\n",
       " 'currently',\n",
       " 'accept',\n",
       " 'situation',\n",
       " 'convey',\n",
       " 'asap',\n",
       " 'correct',\n",
       " 'ringtones',\n",
       " 'less',\n",
       " 'read',\n",
       " 'glad',\n",
       " 'eg',\n",
       " 'confirm',\n",
       " 'nah',\n",
       " 'safe',\n",
       " 'pound',\n",
       " 'knows',\n",
       " 'merry',\n",
       " 'wonder',\n",
       " 'la',\n",
       " 'rd',\n",
       " 'different',\n",
       " 'lover',\n",
       " 'reaching',\n",
       " 'eyes',\n",
       " 'tonite',\n",
       " 'gave',\n",
       " 'representative',\n",
       " 'comin',\n",
       " 'bank',\n",
       " 'terms',\n",
       " 'ans',\n",
       " 'truth',\n",
       " 'normal',\n",
       " 'admirer',\n",
       " 'telling',\n",
       " 'orchard',\n",
       " 'write',\n",
       " 'against',\n",
       " 'meh',\n",
       " 'dead',\n",
       " 'self',\n",
       " 'comp',\n",
       " 'al',\n",
       " 'catch',\n",
       " 'bx',\n",
       " 'none',\n",
       " 'information',\n",
       " 'computer',\n",
       " 'mayb',\n",
       " 'ip',\n",
       " 'disturb',\n",
       " 'exam',\n",
       " 'itself',\n",
       " 'across',\n",
       " 'wkly',\n",
       " 'hospital',\n",
       " 'myself',\n",
       " 'promise',\n",
       " 'cancel',\n",
       " 'lazy',\n",
       " 'noon',\n",
       " 'rates',\n",
       " 'hg',\n",
       " 'ppmx',\n",
       " 'yahoo',\n",
       " 'spent',\n",
       " 'iam',\n",
       " 'rcvd',\n",
       " 'sub',\n",
       " 'monday',\n",
       " 'bold',\n",
       " 'unless',\n",
       " 'outside',\n",
       " 'others',\n",
       " 'booked',\n",
       " 'thinkin',\n",
       " 'askd',\n",
       " 'slave',\n",
       " 'reached',\n",
       " 'questions',\n",
       " 'gn',\n",
       " 'bluetooth',\n",
       " 'usual',\n",
       " 'drugs',\n",
       " 'nobody',\n",
       " 'forever',\n",
       " 'ntt',\n",
       " 'somebody',\n",
       " 'sitting',\n",
       " 'yep',\n",
       " 'slept',\n",
       " 'bill',\n",
       " 'fantastic',\n",
       " 'loan',\n",
       " 'callertune',\n",
       " 'darren',\n",
       " 'ts',\n",
       " 'kids',\n",
       " 'cute',\n",
       " 'kinda',\n",
       " 'pete',\n",
       " 'del',\n",
       " 'link',\n",
       " 'sign',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75967aa0",
   "metadata": {},
   "source": [
    "Now, let's generate a vector for each message in the training data based on the word vectors for each word in that message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96103cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vect = np.array([np.array([w2v_model.wv[i] for i in msg if i in w2v_model.wv.index_to_key]) for msg in X_train], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2d72e",
   "metadata": {},
   "source": [
    "A machine learning model will need the same set of features for each example it sees. In our case, each word is a feature, and the fact that messages have different numbers of words will cause issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee59bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "75 23\n",
      "21 23\n",
      "12 3\n",
      "25 16\n",
      "6 5\n",
      "15 17\n",
      "25 21\n",
      "6 5\n",
      "18 11\n",
      "38 58\n",
      "43 8\n",
      "10 30\n",
      "60 6\n",
      "24 25\n",
      "22 4\n",
      "13 26\n",
      "8 6\n",
      "8 8\n",
      "16 19\n",
      "19 15\n",
      "21 1\n",
      "8 4\n",
      "6 14\n",
      "8 6\n",
      "30 5\n",
      "16 16\n",
      "18 7\n",
      "32 16\n",
      "5 7\n",
      "14 24\n",
      "4 9\n",
      "4 7\n",
      "12 5\n",
      "5 9\n",
      "5 5\n",
      "24 7\n",
      "19 27\n",
      "29 14\n",
      "4 23\n",
      "29 8\n",
      "11 12\n",
      "8 18\n",
      "24 12\n",
      "6 12\n",
      "5 21\n",
      "8 15\n",
      "27 5\n",
      "10 26\n",
      "12 38\n",
      "3 24\n",
      "8 7\n",
      "5 27\n",
      "5 9\n",
      "6 4\n",
      "51 13\n",
      "46 20\n",
      "28 15\n",
      "11 11\n",
      "11 6\n",
      "6 9\n",
      "20 8\n",
      "9 2\n",
      "5 9\n",
      "11 24\n",
      "21 14\n",
      "18 18\n",
      "5 6\n",
      "8 23\n",
      "18 7\n",
      "8 40\n",
      "7 10\n",
      "8 101\n",
      "21 13\n",
      "29 28\n",
      "5 25\n",
      "24 29\n",
      "9 15\n",
      "17 5\n",
      "37 18\n",
      "25 5\n",
      "20 16\n",
      "11 12\n",
      "9 29\n",
      "8 12\n",
      "8 3\n",
      "7 25\n",
      "29 8\n",
      "6 15\n",
      "17 7\n",
      "4 8\n",
      "6 16\n",
      "23 22\n",
      "17 18\n",
      "2 27\n",
      "6 7\n",
      "6 4\n",
      "18 5\n",
      "8 25\n",
      "13 16\n",
      "7 12\n",
      "28 3\n",
      "5 5\n",
      "11 5\n",
      "27 36\n",
      "18 5\n",
      "10 16\n",
      "19 31\n",
      "4 19\n",
      "5 19\n",
      "8 7\n",
      "25 5\n",
      "11 4\n",
      "17 6\n",
      "5 8\n",
      "14 9\n",
      "4 5\n",
      "23 23\n",
      "20 23\n",
      "4 20\n",
      "5 6\n",
      "11 5\n",
      "24 15\n",
      "5 24\n",
      "6 4\n",
      "4 15\n",
      "22 26\n",
      "20 16\n",
      "46 24\n",
      "18 14\n",
      "2 6\n",
      "6 6\n",
      "8 19\n",
      "13 9\n",
      "15 8\n",
      "19 6\n",
      "24 15\n",
      "15 17\n",
      "7 5\n",
      "12 9\n",
      "20 24\n",
      "15 21\n",
      "21 12\n",
      "23 22\n",
      "28 26\n",
      "5 42\n",
      "1 35\n",
      "12 18\n",
      "7 6\n",
      "10 29\n",
      "33 4\n",
      "13 8\n",
      "18 22\n",
      "4 20\n",
      "6 18\n",
      "28 13\n",
      "12 13\n",
      "10 5\n",
      "23 9\n",
      "5 20\n",
      "4 19\n",
      "9 7\n",
      "8 4\n",
      "13 26\n",
      "15 18\n",
      "14 20\n",
      "5 12\n",
      "9 17\n",
      "9 38\n",
      "22 9\n",
      "30 12\n",
      "28 8\n",
      "17 2\n",
      "9 5\n",
      "29 6\n",
      "6 50\n",
      "5 9\n",
      "7 5\n",
      "18 9\n",
      "25 19\n",
      "7 8\n",
      "5 7\n",
      "32 23\n",
      "21 20\n",
      "16 33\n",
      "11 26\n",
      "29 14\n",
      "24 8\n",
      "7 9\n",
      "10 31\n",
      "8 7\n",
      "5 17\n",
      "11 6\n",
      "11 6\n",
      "4 24\n",
      "18 6\n",
      "21 6\n",
      "8 21\n",
      "27 23\n",
      "10 14\n",
      "10 46\n",
      "14 26\n",
      "15 4\n",
      "8 21\n",
      "9 8\n",
      "15 8\n",
      "7 8\n",
      "26 13\n",
      "12 4\n",
      "4 18\n",
      "26 6\n",
      "5 20\n",
      "3 21\n",
      "5 13\n",
      "25 9\n",
      "11 21\n",
      "12 7\n",
      "6 5\n",
      "22 14\n",
      "5 21\n",
      "22 6\n",
      "31 28\n",
      "18 24\n",
      "10 6\n",
      "21 6\n",
      "11 7\n",
      "5 24\n",
      "6 19\n",
      "4 14\n",
      "6 27\n",
      "28 9\n",
      "30 28\n",
      "11 11\n",
      "26 22\n",
      "14 4\n",
      "12 5\n",
      "26 5\n",
      "23 4\n",
      "21 14\n",
      "10 5\n",
      "17 4\n",
      "22 3\n",
      "8 10\n",
      "9 18\n",
      "9 45\n",
      "25 22\n",
      "18 24\n",
      "10 8\n",
      "6 6\n",
      "25 6\n",
      "11 6\n",
      "8 25\n",
      "25 19\n",
      "26 5\n",
      "5 2\n",
      "17 7\n",
      "8 19\n",
      "10 10\n",
      "4 11\n",
      "21 20\n",
      "5 23\n",
      "15 30\n",
      "12 18\n",
      "9 8\n",
      "5 15\n",
      "24 21\n",
      "14 6\n",
      "17 12\n",
      "6 0\n",
      "8 148\n",
      "25 22\n",
      "13 15\n",
      "27 5\n",
      "14 21\n",
      "6 32\n",
      "22 27\n",
      "5 23\n",
      "17 18\n",
      "18 7\n",
      "7 8\n",
      "26 23\n",
      "19 5\n",
      "6 5\n",
      "5 4\n",
      "12 11\n",
      "7 23\n",
      "10 15\n",
      "27 12\n",
      "26 30\n",
      "44 22\n",
      "10 5\n",
      "19 11\n",
      "7 25\n",
      "9 22\n",
      "12 22\n",
      "27 7\n",
      "7 28\n",
      "21 16\n",
      "3 6\n",
      "24 7\n",
      "9 4\n",
      "27 22\n",
      "29 23\n",
      "8 30\n",
      "17 7\n",
      "10 17\n",
      "6 18\n",
      "32 6\n",
      "3 8\n",
      "32 4\n",
      "6 4\n",
      "6 12\n",
      "4 23\n",
      "17 15\n",
      "15 29\n",
      "17 10\n",
      "3 4\n",
      "14 12\n",
      "5 19\n",
      "2 9\n",
      "25 7\n",
      "17 24\n",
      "5 14\n",
      "7 4\n",
      "7 19\n",
      "7 16\n",
      "19 5\n",
      "5 27\n",
      "11 9\n",
      "7 5\n",
      "1 9\n",
      "23 5\n",
      "6 28\n",
      "8 16\n",
      "10 8\n",
      "6 6\n",
      "20 8\n",
      "24 3\n",
      "4 6\n",
      "8 6\n",
      "14 12\n",
      "5 13\n",
      "17 7\n",
      "6 10\n",
      "28 5\n",
      "2 3\n",
      "8 31\n",
      "6 7\n",
      "4 13\n",
      "5 10\n",
      "25 27\n",
      "7 16\n",
      "25 1\n",
      "49 7\n",
      "9 5\n",
      "8 10\n",
      "4 1\n",
      "30 7\n",
      "23 16\n",
      "5 25\n",
      "6 31\n",
      "16 5\n",
      "29 19\n",
      "24 43\n",
      "24 20\n",
      "37 11\n",
      "9 13\n",
      "12 3\n",
      "6 10\n",
      "17 19\n",
      "3 6\n",
      "10 12\n",
      "13 5\n",
      "15 5\n",
      "21 11\n",
      "12 16\n",
      "4 9\n",
      "22 16\n",
      "7 5\n",
      "5 4\n",
      "1 17\n",
      "19 8\n",
      "5 20\n",
      "14 14\n",
      "5 30\n",
      "17 7\n",
      "17 25\n",
      "2 6\n",
      "31 6\n",
      "24 9\n",
      "28 9\n",
      "9 19\n",
      "19 12\n",
      "5 12\n",
      "13 15\n",
      "12 18\n",
      "8 7\n",
      "52 7\n",
      "27 10\n",
      "19 4\n",
      "7 8\n",
      "25 21\n",
      "5 10\n",
      "26 40\n",
      "24 20\n",
      "10 16\n",
      "17 16\n",
      "25 20\n",
      "15 3\n",
      "11 5\n",
      "5 23\n",
      "17 13\n",
      "4 43\n",
      "5 21\n",
      "12 5\n",
      "7 22\n",
      "17 8\n",
      "23 6\n",
      "21 6\n",
      "12 9\n",
      "5 5\n",
      "18 1\n",
      "9 38\n",
      "4 6\n",
      "23 8\n",
      "8 21\n",
      "5 11\n",
      "4 7\n",
      "5 9\n",
      "9 10\n",
      "5 19\n",
      "6 22\n",
      "12 11\n",
      "16 18\n",
      "10 7\n",
      "7 23\n",
      "26 15\n",
      "16 5\n",
      "14 9\n",
      "17 28\n",
      "1 7\n",
      "6 30\n",
      "10 18\n",
      "16 7\n",
      "8 5\n",
      "20 15\n",
      "5 23\n",
      "9 3\n",
      "30 21\n",
      "5 12\n",
      "7 20\n",
      "12 17\n",
      "3 10\n",
      "17 27\n",
      "21 5\n",
      "5 7\n",
      "25 9\n",
      "55 6\n",
      "3 23\n",
      "16 9\n",
      "7 11\n",
      "10 6\n",
      "6 8\n",
      "10 7\n",
      "6 4\n",
      "21 7\n",
      "10 4\n",
      "27 8\n",
      "16 17\n",
      "26 18\n",
      "10 8\n",
      "2 13\n",
      "38 13\n",
      "30 7\n",
      "4 7\n",
      "4 45\n",
      "4 19\n",
      "5 7\n",
      "5 7\n",
      "27 6\n",
      "6 19\n",
      "5 5\n",
      "11 23\n",
      "8 12\n",
      "27 6\n",
      "7 19\n",
      "31 29\n",
      "4 11\n",
      "23 11\n",
      "12 11\n",
      "22 10\n",
      "13 8\n",
      "13 30\n",
      "16 19\n",
      "5 19\n",
      "8 14\n",
      "20 8\n",
      "11 18\n",
      "8 6\n",
      "4 22\n",
      "22 21\n",
      "26 6\n",
      "26 31\n",
      "47 12\n",
      "18 10\n",
      "5 30\n",
      "4 15\n",
      "19 23\n",
      "29 21\n",
      "6 6\n",
      "34 8\n",
      "22 6\n",
      "12 17\n",
      "25 7\n",
      "34 20\n",
      "3 4\n",
      "4 4\n",
      "8 19\n",
      "7 6\n",
      "5 28\n",
      "8 29\n",
      "7 7\n",
      "22 8\n",
      "8 14\n",
      "6 23\n",
      "7 10\n",
      "4 26\n",
      "23 9\n",
      "8 23\n",
      "24 4\n",
      "10 14\n",
      "7 5\n",
      "5 5\n",
      "10 13\n",
      "14 4\n",
      "12 25\n",
      "6 2\n",
      "22 7\n",
      "21 3\n",
      "4 21\n",
      "9 7\n",
      "15 13\n",
      "5 12\n",
      "23 11\n",
      "6 10\n",
      "5 6\n",
      "6 9\n",
      "9 20\n",
      "10 6\n",
      "21 14\n",
      "8 5\n",
      "5 20\n",
      "24 23\n",
      "14 8\n",
      "24 18\n",
      "4 10\n",
      "26 7\n",
      "4 10\n",
      "10 12\n",
      "9 14\n",
      "9 9\n",
      "7 5\n",
      "16 9\n",
      "20 8\n",
      "18 9\n",
      "15 9\n",
      "10 10\n",
      "13 5\n",
      "12 7\n",
      "24 20\n",
      "6 23\n",
      "31 25\n",
      "8 7\n",
      "14 7\n",
      "8 29\n",
      "11 5\n",
      "20 5\n",
      "16 29\n",
      "7 4\n",
      "14 10\n",
      "9 9\n",
      "11 27\n",
      "27 8\n",
      "17 6\n",
      "11 2\n",
      "12 20\n",
      "8 1\n",
      "9 22\n",
      "28 29\n",
      "8 5\n",
      "4 4\n",
      "4 4\n",
      "21 5\n",
      "12 11\n",
      "9 8\n",
      "3 9\n",
      "3 3\n",
      "16 18\n",
      "12 11\n",
      "15 9\n",
      "8 5\n",
      "7 24\n",
      "6 5\n",
      "16 7\n",
      "13 50\n",
      "5 2\n",
      "29 15\n",
      "16 8\n",
      "14 19\n",
      "12 31\n",
      "7 4\n",
      "19 22\n",
      "16 6\n",
      "22 19\n",
      "8 5\n",
      "21 6\n",
      "23 4\n",
      "5 27\n",
      "5 0\n",
      "9 4\n",
      "17 12\n",
      "6 17\n",
      "9 11\n",
      "2 19\n",
      "30 3\n",
      "7 22\n",
      "29 5\n",
      "6 5\n",
      "20 24\n",
      "22 5\n",
      "25 15\n",
      "27 23\n",
      "5 40\n",
      "56 4\n",
      "11 6\n",
      "22 13\n",
      "30 5\n",
      "5 5\n",
      "6 10\n",
      "24 6\n",
      "9 16\n",
      "10 10\n",
      "5 7\n",
      "24 13\n",
      "9 16\n",
      "20 21\n",
      "17 10\n",
      "8 21\n",
      "6 5\n",
      "26 18\n",
      "4 16\n",
      "5 16\n",
      "22 15\n",
      "28 6\n",
      "16 6\n",
      "8 25\n",
      "13 5\n",
      "12 5\n",
      "6 19\n",
      "68 9\n",
      "8 16\n",
      "4 3\n",
      "7 22\n",
      "11 18\n",
      "6 13\n",
      "14 18\n",
      "6 6\n",
      "8 5\n",
      "21 19\n",
      "17 23\n",
      "10 25\n",
      "5 24\n",
      "0 18\n",
      "8 6\n",
      "15 14\n",
      "25 7\n",
      "10 9\n",
      "4 12\n",
      "11 1\n",
      "22 5\n",
      "8 27\n",
      "8 8\n",
      "9 5\n",
      "11 17\n",
      "15 15\n",
      "16 18\n",
      "5 5\n",
      "6 23\n",
      "8 6\n",
      "10 19\n",
      "5 21\n",
      "9 31\n",
      "3 4\n",
      "8 23\n",
      "12 9\n",
      "7 5\n",
      "4 3\n",
      "3 4\n",
      "6 12\n",
      "9 20\n",
      "26 21\n",
      "6 7\n",
      "7 20\n",
      "8 9\n",
      "21 21\n",
      "13 12\n",
      "20 19\n",
      "28 4\n",
      "6 14\n",
      "9 23\n",
      "9 12\n",
      "21 13\n",
      "8 9\n",
      "16 3\n",
      "15 25\n",
      "27 10\n",
      "13 13\n",
      "14 26\n",
      "15 5\n",
      "1 20\n",
      "9 21\n",
      "6 18\n",
      "3 21\n",
      "18 22\n",
      "0 16\n",
      "8 9\n",
      "7 23\n",
      "28 6\n",
      "8 7\n",
      "29 21\n",
      "17 15\n",
      "6 24\n",
      "15 5\n",
      "31 5\n",
      "12 19\n",
      "32 8\n",
      "11 8\n",
      "9 22\n",
      "22 6\n",
      "15 7\n",
      "6 16\n",
      "6 10\n",
      "4 39\n",
      "27 25\n",
      "20 9\n",
      "6 12\n",
      "56 11\n",
      "21 14\n",
      "13 4\n",
      "11 7\n",
      "27 6\n",
      "13 6\n",
      "18 9\n",
      "28 10\n",
      "7 64\n",
      "26 10\n",
      "21 22\n",
      "29 7\n",
      "19 3\n",
      "27 8\n",
      "16 11\n",
      "22 19\n",
      "4 24\n",
      "6 6\n",
      "6 24\n",
      "11 7\n",
      "11 31\n",
      "8 5\n",
      "7 14\n",
      "12 7\n",
      "16 14\n",
      "16 4\n",
      "9 7\n",
      "9 23\n",
      "7 30\n",
      "17 29\n",
      "10 14\n",
      "21 15\n",
      "90 6\n",
      "12 19\n",
      "29 12\n",
      "24 11\n",
      "19 6\n",
      "11 13\n",
      "4 22\n",
      "7 8\n",
      "3 8\n",
      "10 7\n",
      "8 1\n",
      "15 11\n",
      "14 60\n",
      "7 11\n",
      "5 9\n",
      "3 15\n",
      "14 8\n",
      "4 5\n",
      "23 22\n",
      "22 6\n",
      "2 9\n",
      "33 7\n",
      "13 4\n",
      "12 14\n",
      "7 6\n",
      "23 15\n",
      "15 13\n",
      "15 3\n",
      "7 9\n",
      "6 25\n",
      "9 13\n",
      "9 6\n",
      "7 5\n",
      "8 10\n",
      "1 12\n",
      "6 26\n",
      "12 10\n",
      "11 9\n",
      "10 16\n",
      "5 7\n",
      "18 6\n",
      "17 5\n",
      "4 6\n",
      "25 4\n",
      "22 10\n",
      "4 4\n",
      "20 11\n",
      "7 4\n",
      "13 13\n",
      "5 3\n",
      "16 12\n",
      "7 8\n",
      "28 26\n",
      "11 25\n",
      "5 6\n",
      "17 6\n",
      "17 2\n",
      "6 26\n",
      "21 10\n",
      "24 6\n",
      "17 20\n",
      "22 11\n",
      "28 9\n",
      "7 13\n",
      "15 7\n",
      "25 6\n",
      "6 7\n",
      "6 20\n",
      "17 7\n",
      "21 27\n",
      "5 30\n",
      "22 16\n",
      "6 16\n",
      "13 14\n",
      "7 17\n",
      "17 7\n",
      "21 13\n",
      "9 5\n",
      "18 10\n",
      "8 18\n",
      "6 18\n",
      "4 4\n",
      "14 4\n",
      "7 14\n",
      "5 9\n",
      "8 15\n",
      "5 8\n",
      "8 12\n",
      "24 8\n",
      "3 8\n",
      "11 13\n",
      "25 22\n",
      "31 25\n",
      "12 8\n",
      "8 24\n",
      "7 5\n",
      "19 10\n",
      "25 22\n",
      "9 6\n",
      "6 16\n",
      "9 6\n",
      "3 23\n",
      "7 6\n",
      "31 5\n",
      "9 11\n",
      "25 7\n",
      "17 13\n",
      "16 23\n",
      "18 28\n",
      "6 5\n",
      "8 11\n",
      "13 2\n",
      "27 8\n",
      "29 3\n",
      "10 5\n",
      "16 8\n",
      "19 29\n",
      "24 11\n",
      "12 5\n",
      "21 3\n",
      "13 5\n",
      "29 5\n",
      "8 20\n",
      "29 5\n",
      "19 4\n",
      "24 23\n",
      "6 24\n",
      "101 3\n",
      "21 17\n",
      "9 18\n",
      "26 7\n",
      "8 13\n",
      "25 5\n",
      "12 14\n",
      "22 4\n",
      "6 8\n",
      "5 19\n",
      "6 16\n",
      "7 17\n",
      "11 25\n",
      "9 5\n",
      "10 4\n",
      "31 13\n",
      "16 7\n",
      "7 5\n",
      "6 4\n",
      "7 21\n",
      "16 4\n",
      "5 14\n",
      "17 5\n",
      "24 30\n",
      "24 14\n",
      "25 16\n",
      "27 13\n",
      "7 5\n",
      "9 21\n",
      "14 9\n",
      "17 9\n",
      "6 12\n",
      "4 6\n",
      "11 4\n",
      "5 24\n",
      "8 14\n",
      "30 5\n",
      "31 12\n",
      "15 21\n",
      "7 9\n",
      "6 21\n",
      "12 14\n",
      "8 14\n",
      "10 11\n",
      "19 4\n",
      "13 17\n",
      "7 5\n",
      "9 26\n",
      "21 2\n",
      "6 21\n",
      "17 3\n",
      "26 20\n",
      "3 23\n",
      "37 4\n",
      "19 6\n",
      "28 19\n",
      "8 9\n",
      "37 18\n",
      "35 4\n",
      "18 2\n",
      "8 12\n",
      "28 59\n",
      "14 6\n",
      "5 16\n",
      "9 13\n",
      "8 13\n",
      "8 6\n",
      "19 6\n",
      "30 12\n",
      "10 17\n",
      "16 3\n",
      "14 3\n",
      "11 8\n",
      "9 7\n",
      "24 10\n",
      "21 9\n",
      "5 29\n",
      "5 16\n",
      "12 4\n",
      "5 1\n",
      "176 15\n",
      "13 28\n",
      "5 19\n",
      "11 23\n",
      "6 10\n",
      "4 5\n",
      "10 11\n",
      "10 8\n",
      "8 3\n",
      "3 36\n",
      "7 6\n",
      "26 23\n",
      "25 8\n",
      "39 20\n",
      "21 5\n",
      "22 7\n",
      "10 6\n",
      "14 20\n",
      "9 36\n",
      "7 10\n",
      "18 21\n",
      "16 10\n",
      "4 14\n",
      "10 21\n",
      "7 6\n",
      "3 7\n",
      "30 6\n",
      "6 5\n",
      "11 19\n",
      "6 21\n",
      "5 8\n",
      "10 19\n",
      "8 4\n",
      "8 22\n",
      "3 13\n",
      "7 3\n",
      "9 22\n",
      "7 19\n",
      "5 6\n",
      "7 7\n",
      "7 4\n",
      "14 5\n",
      "22 13\n",
      "24 25\n",
      "14 10\n",
      "22 5\n",
      "13 9\n",
      "8 9\n",
      "5 5\n",
      "5 25\n",
      "6 6\n",
      "2 27\n",
      "9 6\n",
      "2 4\n",
      "14 4\n",
      "7 31\n",
      "6 3\n",
      "9 1\n",
      "14 6\n",
      "3 25\n",
      "9 16\n",
      "5 5\n",
      "5 7\n",
      "14 20\n",
      "23 6\n",
      "8 3\n",
      "11 13\n",
      "5 18\n",
      "26 6\n",
      "20 13\n",
      "6 10\n",
      "10 7\n",
      "26 16\n",
      "14 16\n",
      "8 16\n",
      "7 22\n",
      "7 26\n",
      "2 10\n",
      "22 4\n",
      "17 6\n",
      "18 6\n",
      "4 8\n",
      "19 12\n",
      "5 25\n",
      "16 14\n",
      "12 14\n",
      "9 15\n",
      "24 8\n",
      "17 11\n",
      "9 4\n",
      "23 3\n",
      "23 22\n",
      "7 5\n",
      "9 24\n",
      "9 10\n",
      "4 14\n",
      "4 6\n",
      "7 5\n",
      "4 15\n",
      "9 5\n",
      "6 22\n",
      "11 9\n",
      "1 5\n",
      "10 17\n",
      "8 15\n",
      "19 16\n",
      "7 14\n",
      "6 11\n",
      "11 25\n",
      "5 8\n",
      "7 9\n",
      "11 7\n",
      "4 5\n",
      "4 6\n",
      "23 17\n",
      "25 5\n",
      "17 9\n",
      "8 6\n",
      "26 6\n",
      "7 9\n",
      "30 8\n",
      "6 5\n",
      "27 4\n",
      "5 5\n",
      "23 16\n",
      "17 5\n",
      "26 15\n",
      "5 5\n",
      "11 8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dfcff4c1ec8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(w2v_vect): \n",
    "    print(len(X_test.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a7f22",
   "metadata": {},
   "source": [
    "To handle this, we will average all the word vectors we have for a single message together to obtain a single word vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c72386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vect_avg = []\n",
    "\n",
    "for vect in w2v_vect:\n",
    "    if len(vect)!=0:\n",
    "        w2v_vect_avg.append(vect.mean(axis=0))\n",
    "    else:\n",
    "        w2v_vect_avg.append(np.zeros(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665260d0",
   "metadata": {},
   "source": [
    "We check to make sure this fixed our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00696234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 100\n",
      "75 100\n",
      "21 100\n",
      "12 100\n",
      "25 100\n",
      "6 100\n",
      "15 100\n",
      "25 100\n",
      "6 100\n",
      "18 100\n",
      "38 100\n",
      "43 100\n",
      "10 100\n",
      "60 100\n",
      "24 100\n",
      "22 100\n",
      "13 100\n",
      "8 100\n",
      "8 100\n",
      "16 100\n",
      "19 100\n",
      "21 100\n",
      "8 100\n",
      "6 100\n",
      "8 100\n",
      "30 100\n",
      "16 100\n",
      "18 100\n",
      "32 100\n",
      "5 100\n",
      "14 100\n",
      "4 100\n",
      "4 100\n",
      "12 100\n",
      "5 100\n",
      "5 100\n",
      "24 100\n",
      "19 100\n",
      "29 100\n",
      "4 100\n",
      "29 100\n",
      "11 100\n",
      "8 100\n",
      "24 100\n",
      "6 100\n",
      "5 100\n",
      "8 100\n",
      "27 100\n",
      "10 100\n",
      "12 100\n",
      "3 100\n",
      "8 100\n",
      "5 100\n",
      "5 100\n",
      "6 100\n",
      "51 100\n",
      "46 100\n",
      "28 100\n",
      "11 100\n",
      "11 100\n",
      "6 100\n",
      "20 100\n",
      "9 100\n",
      "5 100\n",
      "11 100\n",
      "21 100\n",
      "18 100\n",
      "5 100\n",
      "8 100\n",
      "18 100\n",
      "8 100\n",
      "7 100\n",
      "8 100\n",
      "21 100\n",
      "29 100\n",
      "5 100\n",
      "24 100\n",
      "9 100\n",
      "17 100\n",
      "37 100\n",
      "25 100\n",
      "20 100\n",
      "11 100\n",
      "9 100\n",
      "8 100\n",
      "8 100\n",
      "7 100\n",
      "29 100\n",
      "6 100\n",
      "17 100\n",
      "4 100\n",
      "6 100\n",
      "23 100\n",
      "17 100\n",
      "2 100\n",
      "6 100\n",
      "6 100\n",
      "18 100\n",
      "8 100\n",
      "13 100\n",
      "7 100\n",
      "28 100\n",
      "5 100\n",
      "11 100\n",
      "27 100\n",
      "18 100\n",
      "10 100\n",
      "19 100\n",
      "4 100\n",
      "5 100\n",
      "8 100\n",
      "25 100\n",
      "11 100\n",
      "17 100\n",
      "5 100\n",
      "14 100\n",
      "4 100\n",
      "23 100\n",
      "20 100\n",
      "4 100\n",
      "5 100\n",
      "11 100\n",
      "24 100\n",
      "5 100\n",
      "6 100\n",
      "4 100\n",
      "22 100\n",
      "20 100\n",
      "46 100\n",
      "18 100\n",
      "2 100\n",
      "6 100\n",
      "8 100\n",
      "13 100\n",
      "15 100\n",
      "19 100\n",
      "24 100\n",
      "15 100\n",
      "7 100\n",
      "12 100\n",
      "20 100\n",
      "15 100\n",
      "21 100\n",
      "23 100\n",
      "28 100\n",
      "5 100\n",
      "1 100\n",
      "12 100\n",
      "7 100\n",
      "10 100\n",
      "33 100\n",
      "13 100\n",
      "18 100\n",
      "4 100\n",
      "6 100\n",
      "28 100\n",
      "12 100\n",
      "10 100\n",
      "23 100\n",
      "5 100\n",
      "4 100\n",
      "9 100\n",
      "8 100\n",
      "13 100\n",
      "15 100\n",
      "14 100\n",
      "5 100\n",
      "9 100\n",
      "9 100\n",
      "22 100\n",
      "30 100\n",
      "28 100\n",
      "17 100\n",
      "9 100\n",
      "29 100\n",
      "6 100\n",
      "5 100\n",
      "7 100\n",
      "18 100\n",
      "25 100\n",
      "7 100\n",
      "5 100\n",
      "32 100\n",
      "21 100\n",
      "16 100\n",
      "11 100\n",
      "29 100\n",
      "24 100\n",
      "7 100\n",
      "10 100\n",
      "8 100\n",
      "5 100\n",
      "11 100\n",
      "11 100\n",
      "4 100\n",
      "18 100\n",
      "21 100\n",
      "8 100\n",
      "27 100\n",
      "10 100\n",
      "10 100\n",
      "14 100\n",
      "15 100\n",
      "8 100\n",
      "9 100\n",
      "15 100\n",
      "7 100\n",
      "26 100\n",
      "12 100\n",
      "4 100\n",
      "26 100\n",
      "5 100\n",
      "3 100\n",
      "5 100\n",
      "25 100\n",
      "11 100\n",
      "12 100\n",
      "6 100\n",
      "22 100\n",
      "5 100\n",
      "22 100\n",
      "31 100\n",
      "18 100\n",
      "10 100\n",
      "21 100\n",
      "11 100\n",
      "5 100\n",
      "6 100\n",
      "4 100\n",
      "6 100\n",
      "28 100\n",
      "30 100\n",
      "11 100\n",
      "26 100\n",
      "14 100\n",
      "12 100\n",
      "26 100\n",
      "23 100\n",
      "21 100\n",
      "10 100\n",
      "17 100\n",
      "22 100\n",
      "8 100\n",
      "9 100\n",
      "9 100\n",
      "25 100\n",
      "18 100\n",
      "10 100\n",
      "6 100\n",
      "25 100\n",
      "11 100\n",
      "8 100\n",
      "25 100\n",
      "26 100\n",
      "5 100\n",
      "17 100\n",
      "8 100\n",
      "10 100\n",
      "4 100\n",
      "21 100\n",
      "5 100\n",
      "15 100\n",
      "12 100\n",
      "9 100\n",
      "5 100\n",
      "24 100\n",
      "14 100\n",
      "17 100\n",
      "6 100\n",
      "8 100\n",
      "25 100\n",
      "13 100\n",
      "27 100\n",
      "14 100\n",
      "6 100\n",
      "22 100\n",
      "5 100\n",
      "17 100\n",
      "18 100\n",
      "7 100\n",
      "26 100\n",
      "19 100\n",
      "6 100\n",
      "5 100\n",
      "12 100\n",
      "7 100\n",
      "10 100\n",
      "27 100\n",
      "26 100\n",
      "44 100\n",
      "10 100\n",
      "19 100\n",
      "7 100\n",
      "9 100\n",
      "12 100\n",
      "27 100\n",
      "7 100\n",
      "21 100\n",
      "3 100\n",
      "24 100\n",
      "9 100\n",
      "27 100\n",
      "29 100\n",
      "8 100\n",
      "17 100\n",
      "10 100\n",
      "6 100\n",
      "32 100\n",
      "3 100\n",
      "32 100\n",
      "6 100\n",
      "6 100\n",
      "4 100\n",
      "17 100\n",
      "15 100\n",
      "17 100\n",
      "3 100\n",
      "14 100\n",
      "5 100\n",
      "2 100\n",
      "25 100\n",
      "17 100\n",
      "5 100\n",
      "7 100\n",
      "7 100\n",
      "7 100\n",
      "19 100\n",
      "5 100\n",
      "11 100\n",
      "7 100\n",
      "1 100\n",
      "23 100\n",
      "6 100\n",
      "8 100\n",
      "10 100\n",
      "6 100\n",
      "20 100\n",
      "24 100\n",
      "4 100\n",
      "8 100\n",
      "14 100\n",
      "5 100\n",
      "17 100\n",
      "6 100\n",
      "28 100\n",
      "2 100\n",
      "8 100\n",
      "6 100\n",
      "4 100\n",
      "5 100\n",
      "25 100\n",
      "7 100\n",
      "25 100\n",
      "49 100\n",
      "9 100\n",
      "8 100\n",
      "4 100\n",
      "30 100\n",
      "23 100\n",
      "5 100\n",
      "6 100\n",
      "16 100\n",
      "29 100\n",
      "24 100\n",
      "24 100\n",
      "37 100\n",
      "9 100\n",
      "12 100\n",
      "6 100\n",
      "17 100\n",
      "3 100\n",
      "10 100\n",
      "13 100\n",
      "15 100\n",
      "21 100\n",
      "12 100\n",
      "4 100\n",
      "22 100\n",
      "7 100\n",
      "5 100\n",
      "1 100\n",
      "19 100\n",
      "5 100\n",
      "14 100\n",
      "5 100\n",
      "17 100\n",
      "17 100\n",
      "2 100\n",
      "31 100\n",
      "24 100\n",
      "28 100\n",
      "9 100\n",
      "19 100\n",
      "5 100\n",
      "13 100\n",
      "12 100\n",
      "8 100\n",
      "52 100\n",
      "27 100\n",
      "19 100\n",
      "7 100\n",
      "25 100\n",
      "5 100\n",
      "26 100\n",
      "24 100\n",
      "10 100\n",
      "17 100\n",
      "25 100\n",
      "15 100\n",
      "11 100\n",
      "5 100\n",
      "17 100\n",
      "4 100\n",
      "5 100\n",
      "12 100\n",
      "7 100\n",
      "17 100\n",
      "23 100\n",
      "21 100\n",
      "12 100\n",
      "5 100\n",
      "18 100\n",
      "9 100\n",
      "4 100\n",
      "23 100\n",
      "8 100\n",
      "5 100\n",
      "4 100\n",
      "5 100\n",
      "9 100\n",
      "5 100\n",
      "6 100\n",
      "12 100\n",
      "16 100\n",
      "10 100\n",
      "7 100\n",
      "26 100\n",
      "16 100\n",
      "14 100\n",
      "17 100\n",
      "1 100\n",
      "6 100\n",
      "10 100\n",
      "16 100\n",
      "8 100\n",
      "20 100\n",
      "5 100\n",
      "9 100\n",
      "30 100\n",
      "5 100\n",
      "7 100\n",
      "12 100\n",
      "3 100\n",
      "17 100\n",
      "21 100\n",
      "5 100\n",
      "25 100\n",
      "55 100\n",
      "3 100\n",
      "16 100\n",
      "7 100\n",
      "10 100\n",
      "6 100\n",
      "10 100\n",
      "6 100\n",
      "21 100\n",
      "10 100\n",
      "27 100\n",
      "16 100\n",
      "26 100\n",
      "10 100\n",
      "2 100\n",
      "38 100\n",
      "30 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "5 100\n",
      "5 100\n",
      "27 100\n",
      "6 100\n",
      "5 100\n",
      "11 100\n",
      "8 100\n",
      "27 100\n",
      "7 100\n",
      "31 100\n",
      "4 100\n",
      "23 100\n",
      "12 100\n",
      "22 100\n",
      "13 100\n",
      "13 100\n",
      "16 100\n",
      "5 100\n",
      "8 100\n",
      "20 100\n",
      "11 100\n",
      "8 100\n",
      "4 100\n",
      "22 100\n",
      "26 100\n",
      "26 100\n",
      "47 100\n",
      "18 100\n",
      "5 100\n",
      "4 100\n",
      "19 100\n",
      "29 100\n",
      "6 100\n",
      "34 100\n",
      "22 100\n",
      "12 100\n",
      "25 100\n",
      "34 100\n",
      "3 100\n",
      "4 100\n",
      "8 100\n",
      "7 100\n",
      "5 100\n",
      "8 100\n",
      "7 100\n",
      "22 100\n",
      "8 100\n",
      "6 100\n",
      "7 100\n",
      "4 100\n",
      "23 100\n",
      "8 100\n",
      "24 100\n",
      "10 100\n",
      "7 100\n",
      "5 100\n",
      "10 100\n",
      "14 100\n",
      "12 100\n",
      "6 100\n",
      "22 100\n",
      "21 100\n",
      "4 100\n",
      "9 100\n",
      "15 100\n",
      "5 100\n",
      "23 100\n",
      "6 100\n",
      "5 100\n",
      "6 100\n",
      "9 100\n",
      "10 100\n",
      "21 100\n",
      "8 100\n",
      "5 100\n",
      "24 100\n",
      "14 100\n",
      "24 100\n",
      "4 100\n",
      "26 100\n",
      "4 100\n",
      "10 100\n",
      "9 100\n",
      "9 100\n",
      "7 100\n",
      "16 100\n",
      "20 100\n",
      "18 100\n",
      "15 100\n",
      "10 100\n",
      "13 100\n",
      "12 100\n",
      "24 100\n",
      "6 100\n",
      "31 100\n",
      "8 100\n",
      "14 100\n",
      "8 100\n",
      "11 100\n",
      "20 100\n",
      "16 100\n",
      "7 100\n",
      "14 100\n",
      "9 100\n",
      "11 100\n",
      "27 100\n",
      "17 100\n",
      "11 100\n",
      "12 100\n",
      "8 100\n",
      "9 100\n",
      "28 100\n",
      "8 100\n",
      "4 100\n",
      "4 100\n",
      "21 100\n",
      "12 100\n",
      "9 100\n",
      "3 100\n",
      "3 100\n",
      "16 100\n",
      "12 100\n",
      "15 100\n",
      "8 100\n",
      "7 100\n",
      "6 100\n",
      "16 100\n",
      "13 100\n",
      "5 100\n",
      "29 100\n",
      "16 100\n",
      "14 100\n",
      "12 100\n",
      "7 100\n",
      "19 100\n",
      "16 100\n",
      "22 100\n",
      "8 100\n",
      "21 100\n",
      "23 100\n",
      "5 100\n",
      "5 100\n",
      "9 100\n",
      "17 100\n",
      "6 100\n",
      "9 100\n",
      "2 100\n",
      "30 100\n",
      "7 100\n",
      "29 100\n",
      "6 100\n",
      "20 100\n",
      "22 100\n",
      "25 100\n",
      "27 100\n",
      "5 100\n",
      "56 100\n",
      "11 100\n",
      "22 100\n",
      "30 100\n",
      "5 100\n",
      "6 100\n",
      "24 100\n",
      "9 100\n",
      "10 100\n",
      "5 100\n",
      "24 100\n",
      "9 100\n",
      "20 100\n",
      "17 100\n",
      "8 100\n",
      "6 100\n",
      "26 100\n",
      "4 100\n",
      "5 100\n",
      "22 100\n",
      "28 100\n",
      "16 100\n",
      "8 100\n",
      "13 100\n",
      "12 100\n",
      "6 100\n",
      "68 100\n",
      "8 100\n",
      "4 100\n",
      "7 100\n",
      "11 100\n",
      "6 100\n",
      "14 100\n",
      "6 100\n",
      "8 100\n",
      "21 100\n",
      "17 100\n",
      "10 100\n",
      "5 100\n",
      "0 100\n",
      "8 100\n",
      "15 100\n",
      "25 100\n",
      "10 100\n",
      "4 100\n",
      "11 100\n",
      "22 100\n",
      "8 100\n",
      "8 100\n",
      "9 100\n",
      "11 100\n",
      "15 100\n",
      "16 100\n",
      "5 100\n",
      "6 100\n",
      "8 100\n",
      "10 100\n",
      "5 100\n",
      "9 100\n",
      "3 100\n",
      "8 100\n",
      "12 100\n",
      "7 100\n",
      "4 100\n",
      "3 100\n",
      "6 100\n",
      "9 100\n",
      "26 100\n",
      "6 100\n",
      "7 100\n",
      "8 100\n",
      "21 100\n",
      "13 100\n",
      "20 100\n",
      "28 100\n",
      "6 100\n",
      "9 100\n",
      "9 100\n",
      "21 100\n",
      "8 100\n",
      "16 100\n",
      "15 100\n",
      "27 100\n",
      "13 100\n",
      "14 100\n",
      "15 100\n",
      "1 100\n",
      "9 100\n",
      "6 100\n",
      "3 100\n",
      "18 100\n",
      "0 100\n",
      "8 100\n",
      "7 100\n",
      "28 100\n",
      "8 100\n",
      "29 100\n",
      "17 100\n",
      "6 100\n",
      "15 100\n",
      "31 100\n",
      "12 100\n",
      "32 100\n",
      "11 100\n",
      "9 100\n",
      "22 100\n",
      "15 100\n",
      "6 100\n",
      "6 100\n",
      "4 100\n",
      "27 100\n",
      "20 100\n",
      "6 100\n",
      "56 100\n",
      "21 100\n",
      "13 100\n",
      "11 100\n",
      "27 100\n",
      "13 100\n",
      "18 100\n",
      "28 100\n",
      "7 100\n",
      "26 100\n",
      "21 100\n",
      "29 100\n",
      "19 100\n",
      "27 100\n",
      "16 100\n",
      "22 100\n",
      "4 100\n",
      "6 100\n",
      "6 100\n",
      "11 100\n",
      "11 100\n",
      "8 100\n",
      "7 100\n",
      "12 100\n",
      "16 100\n",
      "16 100\n",
      "9 100\n",
      "9 100\n",
      "7 100\n",
      "17 100\n",
      "10 100\n",
      "21 100\n",
      "90 100\n",
      "12 100\n",
      "29 100\n",
      "24 100\n",
      "19 100\n",
      "11 100\n",
      "4 100\n",
      "7 100\n",
      "3 100\n",
      "10 100\n",
      "8 100\n",
      "15 100\n",
      "14 100\n",
      "7 100\n",
      "5 100\n",
      "3 100\n",
      "14 100\n",
      "4 100\n",
      "23 100\n",
      "22 100\n",
      "2 100\n",
      "33 100\n",
      "13 100\n",
      "12 100\n",
      "7 100\n",
      "23 100\n",
      "15 100\n",
      "15 100\n",
      "7 100\n",
      "6 100\n",
      "9 100\n",
      "9 100\n",
      "7 100\n",
      "8 100\n",
      "1 100\n",
      "6 100\n",
      "12 100\n",
      "11 100\n",
      "10 100\n",
      "5 100\n",
      "18 100\n",
      "17 100\n",
      "4 100\n",
      "25 100\n",
      "22 100\n",
      "4 100\n",
      "20 100\n",
      "7 100\n",
      "13 100\n",
      "5 100\n",
      "16 100\n",
      "7 100\n",
      "28 100\n",
      "11 100\n",
      "5 100\n",
      "17 100\n",
      "17 100\n",
      "6 100\n",
      "21 100\n",
      "24 100\n",
      "17 100\n",
      "22 100\n",
      "28 100\n",
      "7 100\n",
      "15 100\n",
      "25 100\n",
      "6 100\n",
      "6 100\n",
      "17 100\n",
      "21 100\n",
      "5 100\n",
      "22 100\n",
      "6 100\n",
      "13 100\n",
      "7 100\n",
      "17 100\n",
      "21 100\n",
      "9 100\n",
      "18 100\n",
      "8 100\n",
      "6 100\n",
      "4 100\n",
      "14 100\n",
      "7 100\n",
      "5 100\n",
      "8 100\n",
      "5 100\n",
      "8 100\n",
      "24 100\n",
      "3 100\n",
      "11 100\n",
      "25 100\n",
      "31 100\n",
      "12 100\n",
      "8 100\n",
      "7 100\n",
      "19 100\n",
      "25 100\n",
      "9 100\n",
      "6 100\n",
      "9 100\n",
      "3 100\n",
      "7 100\n",
      "31 100\n",
      "9 100\n",
      "25 100\n",
      "17 100\n",
      "16 100\n",
      "18 100\n",
      "6 100\n",
      "8 100\n",
      "13 100\n",
      "27 100\n",
      "29 100\n",
      "10 100\n",
      "16 100\n",
      "19 100\n",
      "24 100\n",
      "12 100\n",
      "21 100\n",
      "13 100\n",
      "29 100\n",
      "8 100\n",
      "29 100\n",
      "19 100\n",
      "24 100\n",
      "6 100\n",
      "101 100\n",
      "21 100\n",
      "9 100\n",
      "26 100\n",
      "8 100\n",
      "25 100\n",
      "12 100\n",
      "22 100\n",
      "6 100\n",
      "5 100\n",
      "6 100\n",
      "7 100\n",
      "11 100\n",
      "9 100\n",
      "10 100\n",
      "31 100\n",
      "16 100\n",
      "7 100\n",
      "6 100\n",
      "7 100\n",
      "16 100\n",
      "5 100\n",
      "17 100\n",
      "24 100\n",
      "24 100\n",
      "25 100\n",
      "27 100\n",
      "7 100\n",
      "9 100\n",
      "14 100\n",
      "17 100\n",
      "6 100\n",
      "4 100\n",
      "11 100\n",
      "5 100\n",
      "8 100\n",
      "30 100\n",
      "31 100\n",
      "15 100\n",
      "7 100\n",
      "6 100\n",
      "12 100\n",
      "8 100\n",
      "10 100\n",
      "19 100\n",
      "13 100\n",
      "7 100\n",
      "9 100\n",
      "21 100\n",
      "6 100\n",
      "17 100\n",
      "26 100\n",
      "3 100\n",
      "37 100\n",
      "19 100\n",
      "28 100\n",
      "8 100\n",
      "37 100\n",
      "35 100\n",
      "18 100\n",
      "8 100\n",
      "28 100\n",
      "14 100\n",
      "5 100\n",
      "9 100\n",
      "8 100\n",
      "8 100\n",
      "19 100\n",
      "30 100\n",
      "10 100\n",
      "16 100\n",
      "14 100\n",
      "11 100\n",
      "9 100\n",
      "24 100\n",
      "21 100\n",
      "5 100\n",
      "5 100\n",
      "12 100\n",
      "5 100\n",
      "176 100\n",
      "13 100\n",
      "5 100\n",
      "11 100\n",
      "6 100\n",
      "4 100\n",
      "10 100\n",
      "10 100\n",
      "8 100\n",
      "3 100\n",
      "7 100\n",
      "26 100\n",
      "25 100\n",
      "39 100\n",
      "21 100\n",
      "22 100\n",
      "10 100\n",
      "14 100\n",
      "9 100\n",
      "7 100\n",
      "18 100\n",
      "16 100\n",
      "4 100\n",
      "10 100\n",
      "7 100\n",
      "3 100\n",
      "30 100\n",
      "6 100\n",
      "11 100\n",
      "6 100\n",
      "5 100\n",
      "10 100\n",
      "8 100\n",
      "8 100\n",
      "3 100\n",
      "7 100\n",
      "9 100\n",
      "7 100\n",
      "5 100\n",
      "7 100\n",
      "7 100\n",
      "14 100\n",
      "22 100\n",
      "24 100\n",
      "14 100\n",
      "22 100\n",
      "13 100\n",
      "8 100\n",
      "5 100\n",
      "5 100\n",
      "6 100\n",
      "2 100\n",
      "9 100\n",
      "2 100\n",
      "14 100\n",
      "7 100\n",
      "6 100\n",
      "9 100\n",
      "14 100\n",
      "3 100\n",
      "9 100\n",
      "5 100\n",
      "5 100\n",
      "14 100\n",
      "23 100\n",
      "8 100\n",
      "11 100\n",
      "5 100\n",
      "26 100\n",
      "20 100\n",
      "6 100\n",
      "10 100\n",
      "26 100\n",
      "14 100\n",
      "8 100\n",
      "7 100\n",
      "7 100\n",
      "2 100\n",
      "22 100\n",
      "17 100\n",
      "18 100\n",
      "4 100\n",
      "19 100\n",
      "5 100\n",
      "16 100\n",
      "12 100\n",
      "9 100\n",
      "24 100\n",
      "17 100\n",
      "9 100\n",
      "23 100\n",
      "23 100\n",
      "7 100\n",
      "9 100\n",
      "9 100\n",
      "4 100\n",
      "4 100\n",
      "7 100\n",
      "4 100\n",
      "9 100\n",
      "6 100\n",
      "11 100\n",
      "1 100\n",
      "10 100\n",
      "8 100\n",
      "19 100\n",
      "7 100\n",
      "6 100\n",
      "11 100\n",
      "5 100\n",
      "7 100\n",
      "11 100\n",
      "4 100\n",
      "4 100\n",
      "23 100\n",
      "25 100\n",
      "17 100\n",
      "8 100\n",
      "26 100\n",
      "7 100\n",
      "30 100\n",
      "6 100\n",
      "27 100\n",
      "5 100\n",
      "23 100\n",
      "17 100\n",
      "26 100\n",
      "5 100\n",
      "11 100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a9fcfb84307a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_vect_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(w2v_vect_avg): \n",
    "    print(len(X_test.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4f401",
   "metadata": {},
   "source": [
    "Now our features are ready to be used in a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc98226",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712738b2",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1218bd5",
   "metadata": {},
   "source": [
    "In this notebook, we introduced Word2Vec, an embedding algorithm that takes a text corpus as input and outputs a vector representation for each word in the corpus. \n",
    "\n",
    "We saw how pre-trained embeddings could be used, as well as how embeddings could be trained using our own data. \n",
    "\n",
    "To finish up, we looked at the last bit of processing needed to be done in order to use the vector representations obtained from our word2vec model in a machine learning model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
