{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02ed578",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "___\n",
    "## Notes\n",
    "In this notebook, we will discuss machine learning as a whole.\n",
    "\n",
    "Specifically, we'll be talking about the following:\n",
    "> [Overview](#Overview:-Machine-Learning)\n",
    ">\n",
    "> [System Evaluation](#System-Evaluation)\n",
    ">\n",
    "> [Random Forests](#Random-Forests)\n",
    ">\n",
    "> [Gradient Boosting](#Gradient-Boosting)\n",
    "\n",
    "We finish the notebook off with a [review](#Review) of everything discussed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f8d3d6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5ff14",
   "metadata": {},
   "source": [
    "> ## Overview: Machine Learning\n",
    "> ___\n",
    "> **Machine Learning** refers to algorithms that use data to make predictions. \n",
    ">\n",
    "> There are two types of machine learning: \n",
    "> - **Supervised Learning**: Learning a mapping function from labeled training data to make predictions on unseen data.\n",
    "> \n",
    "> - **Unsupervised Learning**: Discovering hidden patterns/structures in unlabelled data.\n",
    "> \n",
    "> We will be focusing on supervised learning for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8756ba",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea73e46",
   "metadata": {},
   "source": [
    "> ## System Evaluation\n",
    "> ___\n",
    "> **K-Fold Cross Validation** is a process of dividing a dataset into k subsets where a different holdout subset is used in each iteration to test our model. A nice graphic illustrating this process is shown below.\n",
    "> \n",
    "> INSERT GRAPHIC\n",
    "> \n",
    "> **Evaluation metrics** quantify the performance of our predictive model. \n",
    ">\n",
    "> Here are a few common evaluation metrics we will use:\n",
    "> - $\\text{Accuracy} = \\frac{\\text{# predicted correctly}}{\\text{ total # of observations}}$\n",
    "> - $\\text{Precision} = \\frac{\\text{# predicted as class A that are actually class A}}{\\text{ total # predicted as class A}}$\n",
    "> - $\\text{Recall} = \\frac{\\text{# predicted as class A that are actually class A}}{\\text{ total # that are actually class A}}$\n",
    ">\n",
    "> `Note`: If we want to limit false positives, we will optimize the model for precision. If we want to limit false negatives, we will optomize the model for recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18e88b",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e70e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79bc89fc",
   "metadata": {},
   "source": [
    "> ## Random Forests\n",
    "> \n",
    "> **Random forests** are collections of decision trees whose predictions aggregated to obtain a final prediction. \n",
    "> \n",
    "> They use **ensemble learning**, a process by which multiple models are created and combined to make a more informed prediction (compared to a single model). \n",
    ">\n",
    "> As with any other model, we can use things like **k-fold cross validation** and **train-test splits** to evaluate our random forests. We can also use things like **grid-search**, an exhaustive search process across all parameter combinations in a given grid for the best performing parameters, to improve our random forests. \n",
    ">\n",
    "> Let's explore random forests a bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e5270f",
   "metadata": {},
   "source": [
    "First, we'll read in our data and clean it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf2f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.tsv', sep='\\t', header=None)\n",
    "data.columns = ['label','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3427bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuation(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")),3)*100\n",
    "\n",
    "data['length'] = data['text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punctuation'] = data['text'].apply(lambda x: count_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1375ab19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8181</th>\n",
       "      <th>8182</th>\n",
       "      <th>8183</th>\n",
       "      <th>8184</th>\n",
       "      <th>8185</th>\n",
       "      <th>8186</th>\n",
       "      <th>8187</th>\n",
       "      <th>8188</th>\n",
       "      <th>8189</th>\n",
       "      <th>8190</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  punctuation    0    1    2    3    4    5    6    7  ...  8181  \\\n",
       "0     160          2.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1     128          4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2      49          4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3      62          3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4      28          7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   8182  8183  8184  8185  8186  8187  8188  8189  8190  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8193 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    tokenized_text = re.split('\\W+',cleaned_text)\n",
    "    stemmed_tokens = [ps.stem(word) for word in tokenized_text if word not in stopwords]\n",
    "    return stemmed_tokens\n",
    "\n",
    "tdidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf_counts = tdidf_vect.fit_transform(data['text'])\n",
    "\n",
    "X_features = pd.concat([data['length'], data['punctuation'], pd.DataFrame(X_tfidf_counts.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8fe02",
   "metadata": {},
   "source": [
    "Now, let's import our `RandomForestClassifier` and explore it through 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47819d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98384201, 0.96947935, 0.97666068, 0.98743268, 0.97307002,\n",
       "       0.98025135, 0.97127469, 0.96947935, 0.9676259 , 0.98201439])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1) # allows for trees to run in parallel\n",
    "k_fold = KFold(n_splits=10)\n",
    "cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce7b50",
   "metadata": {},
   "source": [
    "Let's explore our `RandomForestClassifier` using a holdout test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12df01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size = 0.2)\n",
    "rf2 = RandomForestClassifier(n_estimators= 50,max_depth=20, n_jobs=-1)\n",
    "rf2_model = rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a794b4",
   "metadata": {},
   "source": [
    "Our `RandomForestClassifier` has a `feature_importances_` attribute we would like to make use of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ca43a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.04727789288599296, 'length'),\n",
       " (0.039905742377050364, 2048),\n",
       " (0.02900918223533704, 1819),\n",
       " (0.0245632355485361, 7090),\n",
       " (0.023629581186565912, 4838),\n",
       " (0.02316410225353268, 3159),\n",
       " (0.021391812063942965, 295),\n",
       " (0.020058904539315043, 7422),\n",
       " (0.019354545728288715, 2188),\n",
       " (0.017632349642892228, 7864)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf2_model.feature_importances_, X_train.columns), reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159cfe9",
   "metadata": {},
   "source": [
    "The above results tell us that the length of text is a key factor in determining labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90dab74",
   "metadata": {},
   "source": [
    "Let's go ahead and make predictions using our model (since we've already fit the model to our training data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bde6a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.57\n",
      "Accuracy: 0.942\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf2_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Precision: {}'.format(round(precision,3)))\n",
    "print('Recall: {}'.format(round(recall,3)))\n",
    "print('Accuracy: {}'.format(round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae062a",
   "metadata": {},
   "source": [
    "The above results tell us that:\n",
    "- 100% mail in the spam folder is actually spam\n",
    "- 57% of all spam was properly marked as spam\n",
    "- 94.2% of all emails were identified correctly (whether spam or ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed5ec7",
   "metadata": {},
   "source": [
    "To finish up, let's perform a grid-search for our `RandomForestClassifier`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dd9ef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 --- Precision: 1.0 / Recall: 0.146 / Accuracy: 0.884\n",
      "Est: 10 / Depth: 20 --- Precision: 1.0 / Recall: 0.57 / Accuracy: 0.942\n",
      "Est: 10 / Depth: 30 --- Precision: 1.0 / Recall: 0.742 / Accuracy: 0.965\n",
      "Est: 10 / Depth: None --- Precision: 0.991 / Recall: 0.755 / Accuracy: 0.966\n",
      "Est: 50 / Depth: 10 --- Precision: 1.0 / Recall: 0.238 / Accuracy: 0.897\n",
      "Est: 50 / Depth: 20 --- Precision: 1.0 / Recall: 0.55 / Accuracy: 0.939\n",
      "Est: 50 / Depth: 30 --- Precision: 1.0 / Recall: 0.675 / Accuracy: 0.956\n",
      "Est: 50 / Depth: None --- Precision: 1.0 / Recall: 0.801 / Accuracy: 0.973\n",
      "Est: 100 / Depth: 10 --- Precision: 1.0 / Recall: 0.258 / Accuracy: 0.899\n",
      "Est: 100 / Depth: 20 --- Precision: 1.0 / Recall: 0.536 / Accuracy: 0.937\n",
      "Est: 100 / Depth: 30 --- Precision: 1.0 / Recall: 0.682 / Accuracy: 0.957\n",
      "Est: 100 / Depth: None --- Precision: 1.0 / Recall: 0.815 / Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "def train_rf(num_estimators, depth_num):\n",
    "    rf = RandomForestClassifier(n_estimators=num_estimators, max_depth=depth_num, n_jobs=-1)\n",
    "    rf_model = rf.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} --- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        num_estimators, depth_num, round(precision,3), round(recall,3), \n",
    "        round((y_pred==y_test).sum() / len(y_pred),3)))\n",
    "\n",
    "for num_estimators in [10, 50, 100]:\n",
    "    for depth_num in [10, 20, 30, None]:\n",
    "        train_rf(num_estimators, depth_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dcaf4d",
   "metadata": {},
   "source": [
    "The above results tell us that:\n",
    "- As depth increase, recall increases drastically without a change in precision\n",
    "- As estimators increase, recall increases slightly without a change in precision\n",
    "\n",
    "Therefore, the best random forest model for this problem would be one with a very high depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cf187",
   "metadata": {},
   "source": [
    "We could also perform grid-search using `GridSearchCV`, which simultaneously performs cross-validation for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc841c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.201188</td>\n",
       "      <td>0.194872</td>\n",
       "      <td>0.433598</td>\n",
       "      <td>0.092399</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.974855</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.388246</td>\n",
       "      <td>1.089177</td>\n",
       "      <td>0.423114</td>\n",
       "      <td>0.065336</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.974316</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30.940607</td>\n",
       "      <td>4.130551</td>\n",
       "      <td>0.267455</td>\n",
       "      <td>0.066316</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.974316</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.967187</td>\n",
       "      <td>1.712187</td>\n",
       "      <td>0.449691</td>\n",
       "      <td>0.107516</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.974136</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.674996</td>\n",
       "      <td>0.421129</td>\n",
       "      <td>0.382897</td>\n",
       "      <td>0.068638</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.973957</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       22.201188      0.194872         0.433598        0.092399   \n",
       "4       20.388246      1.089177         0.423114        0.065336   \n",
       "11      30.940607      4.130551         0.267455        0.066316   \n",
       "8       39.967187      1.712187         0.449691        0.107516   \n",
       "10      22.674996      0.421129         0.382897        0.068638   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "4               60                150   \n",
       "11            None                300   \n",
       "8               90                300   \n",
       "10            None                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.976661   \n",
       "4     {'max_depth': 60, 'n_estimators': 150}           0.978456   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.977558   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.976661   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.978456   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.977558           0.976661           0.967655   \n",
       "4            0.977558           0.973968           0.967655   \n",
       "11           0.978456           0.976661           0.965858   \n",
       "8            0.979354           0.974865           0.967655   \n",
       "10           0.977558           0.973968           0.966757   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.975741         0.974855        0.003646                1  \n",
       "4            0.973944         0.974316        0.003802                2  \n",
       "11           0.973046         0.974316        0.004611                3  \n",
       "8            0.972147         0.974136        0.004002                4  \n",
       "10           0.973046         0.973957        0.004145                5  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf3 = RandomForestClassifier()\n",
    "param = {'n_estimators':[10, 150, 300],\n",
    "        'max_depth':[30, 60, 90, None]} #defining our grid as a dictionary\n",
    "\n",
    "gs = GridSearchCV(rf3, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_features, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5] #print some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c242b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.209251</td>\n",
       "      <td>0.047505</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.964061</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.972341</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.431940</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 10}</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.972161</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.054038</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.085057</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.964061</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.971982</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.677317</td>\n",
       "      <td>0.693079</td>\n",
       "      <td>0.143896</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.971981</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.601500</td>\n",
       "      <td>1.343673</td>\n",
       "      <td>0.121324</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.971623</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7        7.209251      0.047505         0.078798        0.001776   \n",
       "6        0.431940      0.008801         0.007970        0.000222   \n",
       "10       8.054038      0.081710         0.085057        0.005951   \n",
       "8       13.677317      0.693079         0.143896        0.017107   \n",
       "11      11.601500      1.343673         0.121324        0.006759   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "6               90                 10   \n",
       "10            None                150   \n",
       "8               90                300   \n",
       "11            None                300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.976661   \n",
       "6      {'max_depth': 90, 'n_estimators': 10}           0.974865   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.977558   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.976661   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.977558   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.972172           0.974865           0.964061   \n",
       "6            0.973968           0.977558           0.966757   \n",
       "10           0.971275           0.972172           0.964061   \n",
       "8            0.974865           0.972172           0.967655   \n",
       "11           0.971275           0.971275           0.965858   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.973944         0.972341        0.004386                1  \n",
       "6            0.967655         0.972161        0.004224                2  \n",
       "10           0.974843         0.971982        0.004529                3  \n",
       "8            0.968553         0.971981        0.003485                4  \n",
       "11           0.972147         0.971623        0.003714                5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit2 = gs.fit(X_tfidf_counts, data['label'])\n",
    "pd.DataFrame(gs_fit2.cv_results_).sort_values('mean_test_score', ascending=False)[0:5] #print some results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8ea47",
   "metadata": {},
   "source": [
    "The above results tell us that deeper models tend to perform better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440d7f4",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8d343",
   "metadata": {},
   "source": [
    "> ## Gradient Boosting\n",
    "> \n",
    "> **Gradient Boosting** is an ensemble method, based on decision trees, that combines weak learners together to generate a strong learner. Specifically, mistakes made in prior iterations heavily impact future iterations in gradient boosting. \n",
    ">\n",
    "> Typically, <u>gradient boosting</u> takes longer to train and is much easier to overfit when compared to <u>random forsts</u>. However, gradient boost generally performs much better in comparison. \n",
    ">\n",
    "> Let's dive into gradient boosting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "def17ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def train_GB(est, max_depth, lr):\n",
    "    gb = GradientBoostingClassifier(n_estimators=est, max_depth=max_depth, learning_rate=lr)\n",
    "    gb_model = gb.fit(X_train, y_train)\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} / LR: {} --- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        num_estimators, depth_num, lr, round(precision,3), round(recall,3), \n",
    "        round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e153382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zwilkerson/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.864\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.972 / Recall: 0.702 / Accuracy: 0.957\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.888 / Recall: 0.788 / Accuracy: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zwilkerson/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.864\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.93 / Recall: 0.788 / Accuracy: 0.963\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.871 / Recall: 0.808 / Accuracy: 0.958\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 1.0 / Recall: 0.007 / Accuracy: 0.865\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.909 / Recall: 0.795 / Accuracy: 0.961\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.911 / Recall: 0.815 / Accuracy: 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zwilkerson/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.864\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.896 / Recall: 0.801 / Accuracy: 0.961\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.9 / Recall: 0.834 / Accuracy: 0.965\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.963 / Recall: 0.523 / Accuracy: 0.933\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.973 / Recall: 0.728 / Accuracy: 0.961\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.894 / Recall: 0.781 / Accuracy: 0.958\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.933 / Recall: 0.642 / Accuracy: 0.945\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.945 / Recall: 0.801 / Accuracy: 0.967\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.923 / Recall: 0.795 / Accuracy: 0.963\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.909 / Recall: 0.728 / Accuracy: 0.953\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.917 / Recall: 0.808 / Accuracy: 0.964\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.945 / Recall: 0.795 / Accuracy: 0.966\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.91 / Recall: 0.735 / Accuracy: 0.954\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.91 / Recall: 0.808 / Accuracy: 0.963\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.939 / Recall: 0.815 / Accuracy: 0.968\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.964 / Recall: 0.53 / Accuracy: 0.934\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.959 / Recall: 0.775 / Accuracy: 0.965\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.899 / Recall: 0.768 / Accuracy: 0.957\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.938 / Recall: 0.695 / Accuracy: 0.952\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.953 / Recall: 0.808 / Accuracy: 0.969\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.932 / Recall: 0.815 / Accuracy: 0.967\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.895 / Recall: 0.735 / Accuracy: 0.952\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.931 / Recall: 0.808 / Accuracy: 0.966\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.932 / Recall: 0.815 / Accuracy: 0.967\n",
      "Est: 100 / Depth: None / LR: 0.01 --- Precision: 0.898 / Recall: 0.755 / Accuracy: 0.955\n",
      "Est: 100 / Depth: None / LR: 0.1 --- Precision: 0.897 / Recall: 0.808 / Accuracy: 0.961\n",
      "Est: 100 / Depth: None / LR: 1 --- Precision: 0.947 / Recall: 0.828 / Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "for n_est in [50, 100, 150]:\n",
    "    for max_depth in [3, 7, 11, 13]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            train_GB(n_est, max_depth, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d341d31",
   "metadata": {},
   "source": [
    "The above results tell us that:\n",
    "- A learning rate of 0.1 appears to give the best performance\n",
    "- A large max depth appears to give the best performance\n",
    "- A large number of estimators appears to give the best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f92d2b",
   "metadata": {},
   "source": [
    "What if we want to evaluate gradient boosting with `GridSearchCV`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2716bae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8181</th>\n",
       "      <th>8182</th>\n",
       "      <th>8183</th>\n",
       "      <th>8184</th>\n",
       "      <th>8185</th>\n",
       "      <th>8186</th>\n",
       "      <th>8187</th>\n",
       "      <th>8188</th>\n",
       "      <th>8189</th>\n",
       "      <th>8190</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  punctuation    0    1    2    3    4    5    6    7  ...  8181  \\\n",
       "0     160          2.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1     128          4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2      49          4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3      62          3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4      28          7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   8182  8183  8184  8185  8186  8187  8188  8189  8190  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8193 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# TF-IDF\n",
    "tdidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tdidf_vect.fit_transform(data['text'])\n",
    "X_tfidf_feat = pd.concat([data['length'], data['punctuation'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = tdidf_vect.fit_transform(data['text'])\n",
    "X_count_feat = pd.concat([data['length'], data['punctuation'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "\n",
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57be797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150], # based on last section\n",
    "    'max_depth': [7, 11, 15], # based on last section\n",
    "    'learning_rate': [0.1] # default learning rate, so don't need to include\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(gb, param, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b57f66ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-334b2d297a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit2 = gs.fit(X_count, data['label'])\n",
    "pd.DataFrame(cv_fit2.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e45ab",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "So far, we've been making a mistake. We were fitting our model with all the data, then splitting it into training and testing. We did this to make using GridSearchCV easier for us, but now we'll go ahead and correct this mistake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e5905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.tsv', sep='\\t', header=None)\n",
    "data.columns = ['label','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b36475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuation(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")),3)*100\n",
    "\n",
    "data['length'] = data['text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punctuation'] = data['text'].apply(lambda x: count_punctuation(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    tokenized_text = re.split('\\W+',cleaned_text)\n",
    "    stemmed_tokens = [ps.stem(word) for word in tokenized_text if word not in stopwords]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09907118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['text','length','punctuation']], data['label'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0013cd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7297</th>\n",
       "      <th>7298</th>\n",
       "      <th>7299</th>\n",
       "      <th>7300</th>\n",
       "      <th>7301</th>\n",
       "      <th>7302</th>\n",
       "      <th>7303</th>\n",
       "      <th>7304</th>\n",
       "      <th>7305</th>\n",
       "      <th>7306</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  punctuation    0    1    2    3    4    5    6    7  ...  7297  \\\n",
       "0      39          7.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1      46         13.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2      30          6.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3      41          7.3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4     131          9.9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   7298  7299  7300  7301  7302  7303  7304  7305  7306  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7309 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['length','punctuation']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1) # 1 = side-by-side, 0 = on top of each other\n",
    "X_test_vect = pd.concat([X_test[['length','punctuation']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1) # 1 = side-by-side, 0 = on top of each other\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56177fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fca4df02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Time: 2.232 / Predict Time: 0.15 --- Precision: 1.0 / Recall: 0.82 / Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "end = time()\n",
    "fit_time = (end-start)\n",
    "\n",
    "start = time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end = time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Fit Time: {} / Predict Time: {} --- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3),round(precision,3), round(recall,3), round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42d41df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Time: 171.472 / Predict Time: 0.173 --- Precision: 0.971 / Recall: 0.845 / Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "start = time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "end = time()\n",
    "fit_time = (end-start)\n",
    "\n",
    "start = time()\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "end = time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Fit Time: {} / Predict Time: {} --- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3),round(precision,3), round(recall,3), round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719de07",
   "metadata": {},
   "source": [
    "We would also want to perform further evaluation, such as:\n",
    "- Examining certain text message types to see models performance\n",
    "    - Text messages that are longer than 50 charactes\n",
    "    - Text messages with no punctuation\n",
    "    - and more...\n",
    "    \n",
    "Is prediction time a bottleneck for you business? Do you prefer one metrics performance over the other -- is precision more important than recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047e847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
